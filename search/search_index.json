{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"kjournal \u00b6 kjournal closes the gap between long-term log storage and your client. kjournal is a simple and lightweight kubernetes api server which makes your longterm log storage available as consumable readonly kubernetes api. With kjournal you can easily access container logs from old (and current pods) as well as other long-term logs including out of the box support for kubernetes audit logs and events. Documention \u00b6 Want to get started? Please read the documentation here .","title":"Home"},{"location":"#kjournal","text":"kjournal closes the gap between long-term log storage and your client. kjournal is a simple and lightweight kubernetes api server which makes your longterm log storage available as consumable readonly kubernetes api. With kjournal you can easily access container logs from old (and current pods) as well as other long-term logs including out of the box support for kubernetes audit logs and events.","title":"kjournal"},{"location":"#documention","text":"Want to get started? Please read the documentation here .","title":"Documention"},{"location":"contributing/","text":"Release process \u00b6 Controller release \u00b6 Merge all pr's to master which need to be part of the new release Create pr to master with these changes: Bump kustomization Create CHANGELOG.md entry with release and date Merge pr Push a tag following semantic versioning prefixed by 'v'. Do not create a github release, this is done automatically. Create new branch and add the following changes: Bump chart version Bump charts app version Create pr to master and merge Helm chart change only \u00b6 Create branch with changes Bump chart version Create pr to master and merge","title":"Contributing"},{"location":"contributing/#release-process","text":"","title":"Release process"},{"location":"contributing/#controller-release","text":"Merge all pr's to master which need to be part of the new release Create pr to master with these changes: Bump kustomization Create CHANGELOG.md entry with release and date Merge pr Push a tag following semantic versioning prefixed by 'v'. Do not create a github release, this is done automatically. Create new branch and add the following changes: Bump chart version Bump charts app version Create pr to master and merge","title":"Controller release"},{"location":"contributing/#helm-chart-change-only","text":"Create branch with changes Bump chart version Create pr to master and merge","title":"Helm chart change only"},{"location":"goals/","text":"Project goals \u00b6 Goals \u00b6 A kubernetes native solution to serve logs as a kubernetes API. It may bee seen as an extension to the integrated logs API endpoint. However the goal for kjournal is to expose logs from the longterm log storage back to kubernetes api consumers. Logs should be searchable, watchable and consumable in a kubernete style manner. Likewise log endpoints must RBAC protected as and consumable via a kubernetes signed authentication token. Summary: Log server which provides historical kubernetes events Log server which provides historical container logs Log server which provides historical audit logs Log server which provides histroical generic logs (unstructered log data) Expose these as kubernetes APIS Provider kubernetes API aggregation Support RBAC (which includes authentication and authorization) Support multiple storage backends. Especially elasticsearch. More backends are considered like Loki. Non goals \u00b6 It is not the job of kjournal to feed the kubernetes logs into your longterm storage solution. For this part various tooling exists. The job of kjournal is rather the other way around. kjournal itself does * not - store any data. It serves logs from a backing storage.","title":"Project goals"},{"location":"goals/#project-goals","text":"","title":"Project goals"},{"location":"goals/#goals","text":"A kubernetes native solution to serve logs as a kubernetes API. It may bee seen as an extension to the integrated logs API endpoint. However the goal for kjournal is to expose logs from the longterm log storage back to kubernetes api consumers. Logs should be searchable, watchable and consumable in a kubernete style manner. Likewise log endpoints must RBAC protected as and consumable via a kubernetes signed authentication token. Summary: Log server which provides historical kubernetes events Log server which provides historical container logs Log server which provides historical audit logs Log server which provides histroical generic logs (unstructered log data) Expose these as kubernetes APIS Provider kubernetes API aggregation Support RBAC (which includes authentication and authorization) Support multiple storage backends. Especially elasticsearch. More backends are considered like Loki.","title":"Goals"},{"location":"goals/#non-goals","text":"It is not the job of kjournal to feed the kubernetes logs into your longterm storage solution. For this part various tooling exists. The job of kjournal is rather the other way around. kjournal itself does * not - store any data. It serves logs from a backing storage.","title":"Non goals"},{"location":"how-it-works/","text":"How it works \u00b6 kjournal is a kubernetes compatible apiserver. Read more about the kubernetes apiserver aggregation here . graph LR A[<b>kjournal-cli</b>] B[<b>kube-apiserver</b>] C[<b>kjournal-apiserver</b>] D[<b>longterm log storage</b></br>elasticsearch,gcloud,...] E[<b>log shipper</b></br>fluent-bit,fluent,filebeat,...] A --> B; B -->|API-Aggregation| C; C --> D; E ---> D; Expose longterm logs using kjournal \u00b6 To close the gap again between the longterm storage and kubernetes is kjournals job. The kjournal-apiserver exposes a single api group core.kjournal with containerlogs , events , auditevents and logs as resources which makes logs accessible to kubernetes tooling. The kjournal-apiserver talks to the longterm storage while clients including kjournal or kubectl talk only to the kjournal-apiserver (via the kube-apiserver). Logging in kubernetes \u00b6 Kubernetes container logs \u00b6 Kubernetes stores all container logs on the nodes for a limited time. The logs get rotated and logs from older containers are not accessible at at all and are lost if not persisted elsewhere. It is commonly known a good practice to gather these container logs and make them available in a longterm log storage. These logs are then accessible using third party tooling and are out of the kubernetes toolchain. Read more about the kubernetes logging architecture . Kubernetes audit logs \u00b6 The kube-apiserver can be configured to store audit events for all requests going to the apiserver. Similar to container logs these events are usually stored in log files directly on the master node(s). Like for container logs these logs should be persisted into longterm storage to make them available over time. Kubernetes events \u00b6 Kubernetes events are not logs directly. Rather they are evens emitted by reconcilers and stored as normal kubernetes resource in the backing storage (etcd). These events live only for one hour and are removed after. kjournal exposes the same API and makes these events available from the longterm log storage.","title":"How it works"},{"location":"how-it-works/#how-it-works","text":"kjournal is a kubernetes compatible apiserver. Read more about the kubernetes apiserver aggregation here . graph LR A[<b>kjournal-cli</b>] B[<b>kube-apiserver</b>] C[<b>kjournal-apiserver</b>] D[<b>longterm log storage</b></br>elasticsearch,gcloud,...] E[<b>log shipper</b></br>fluent-bit,fluent,filebeat,...] A --> B; B -->|API-Aggregation| C; C --> D; E ---> D;","title":"How it works"},{"location":"how-it-works/#expose-longterm-logs-using-kjournal","text":"To close the gap again between the longterm storage and kubernetes is kjournals job. The kjournal-apiserver exposes a single api group core.kjournal with containerlogs , events , auditevents and logs as resources which makes logs accessible to kubernetes tooling. The kjournal-apiserver talks to the longterm storage while clients including kjournal or kubectl talk only to the kjournal-apiserver (via the kube-apiserver).","title":"Expose longterm logs using kjournal"},{"location":"how-it-works/#logging-in-kubernetes","text":"","title":"Logging in kubernetes"},{"location":"how-it-works/#kubernetes-container-logs","text":"Kubernetes stores all container logs on the nodes for a limited time. The logs get rotated and logs from older containers are not accessible at at all and are lost if not persisted elsewhere. It is commonly known a good practice to gather these container logs and make them available in a longterm log storage. These logs are then accessible using third party tooling and are out of the kubernetes toolchain. Read more about the kubernetes logging architecture .","title":"Kubernetes container logs"},{"location":"how-it-works/#kubernetes-audit-logs","text":"The kube-apiserver can be configured to store audit events for all requests going to the apiserver. Similar to container logs these events are usually stored in log files directly on the master node(s). Like for container logs these logs should be persisted into longterm storage to make them available over time.","title":"Kubernetes audit logs"},{"location":"how-it-works/#kubernetes-events","text":"Kubernetes events are not logs directly. Rather they are evens emitted by reconcilers and stored as normal kubernetes resource in the backing storage (etcd). These events live only for one hour and are removed after. kjournal exposes the same API and makes these events available from the longterm log storage.","title":"Kubernetes events"},{"location":"quick-start/","text":"Quick Start \u00b6 Note If you are a cluster admin a and want to deploy kjournal on your cluster(s), please refer to the apiserver install guide . Install CLI \u00b6 Brew Go Bash Docker brew install raffis/kjournal/kjournal go install github.com/raffis/kjournal/cli/cmd@latest curl -sfL https://raw.githubusercontent.com/raffis/kjournal/main/cli/install/kjournal.sh | bash docker pull ghcr.io/raffis/kjournal/cli:latest You will find in the CLI installation documentation more advanced options regarding the cli installation. Fetch logs \u00b6 Containers \u00b6 To fetch container logs from a namespace you can simply use the pods command. The command will start to print log streams from all containers prefixed and colored by pod and container names. This will display all container logs from the namespace mynamespace . kjournal pods -n mynamespace You can quick filter by naming a pod or a pod prefix. Will stream logs from all pods starting with mypod- kjournal pods -n mynamespace mypod- Events \u00b6 Get historical kubernetes events. kjournal events -n mynamespace Audit events \u00b6 kjournal has built-in support for kubernetes audit events. You can access audit event using the audit command. This will stream the entire audit feed: kjournal audit Note AuditEvent is a cluster scoped resource and needs cluster wide permission to read it. Arbitary logs \u00b6 Get arbitary logs. kjournal logs Note Logs is a cluster scoped resource and needs cluster wide permission to read it. Time range \u00b6 The kjournal-apiserver looks up logs from the last 24 hours and starts stream from 24h ago. The server default is configurable (see server configuration). You can change the window in which logs are looked up by using the --since flag. This works for all kjournal commands. This will stream logs starting from 7 days ago. kjournal pods -n mynamespace mypod- --since 7d Alternatively you may use --range [from]-[to] . --range 18h-23h will feed logs from 18h ago to 23h ago, basically a 5h window. Note --since is a shortcut of --range now-[to] . --since 5h is the same as --range now-5h . Filter \u00b6 Logs can be filtered server-side. This works for all kjournal commands. You can use the flag --field-selector which supports the same operators as kubectl get does. However on top of that kjournal also supports other operators including > , < or in() . kjournal pods -n mynamespace mypod- --field-selector payload.myLogField = xxx","title":"Quick Start"},{"location":"quick-start/#quick-start","text":"Note If you are a cluster admin a and want to deploy kjournal on your cluster(s), please refer to the apiserver install guide .","title":"Quick Start"},{"location":"quick-start/#install-cli","text":"Brew Go Bash Docker brew install raffis/kjournal/kjournal go install github.com/raffis/kjournal/cli/cmd@latest curl -sfL https://raw.githubusercontent.com/raffis/kjournal/main/cli/install/kjournal.sh | bash docker pull ghcr.io/raffis/kjournal/cli:latest You will find in the CLI installation documentation more advanced options regarding the cli installation.","title":"Install CLI"},{"location":"quick-start/#fetch-logs","text":"","title":"Fetch logs"},{"location":"quick-start/#containers","text":"To fetch container logs from a namespace you can simply use the pods command. The command will start to print log streams from all containers prefixed and colored by pod and container names. This will display all container logs from the namespace mynamespace . kjournal pods -n mynamespace You can quick filter by naming a pod or a pod prefix. Will stream logs from all pods starting with mypod- kjournal pods -n mynamespace mypod-","title":"Containers"},{"location":"quick-start/#events","text":"Get historical kubernetes events. kjournal events -n mynamespace","title":"Events"},{"location":"quick-start/#audit-events","text":"kjournal has built-in support for kubernetes audit events. You can access audit event using the audit command. This will stream the entire audit feed: kjournal audit Note AuditEvent is a cluster scoped resource and needs cluster wide permission to read it.","title":"Audit events"},{"location":"quick-start/#arbitary-logs","text":"Get arbitary logs. kjournal logs Note Logs is a cluster scoped resource and needs cluster wide permission to read it.","title":"Arbitary logs"},{"location":"quick-start/#time-range","text":"The kjournal-apiserver looks up logs from the last 24 hours and starts stream from 24h ago. The server default is configurable (see server configuration). You can change the window in which logs are looked up by using the --since flag. This works for all kjournal commands. This will stream logs starting from 7 days ago. kjournal pods -n mynamespace mypod- --since 7d Alternatively you may use --range [from]-[to] . --range 18h-23h will feed logs from 18h ago to 23h ago, basically a 5h window. Note --since is a shortcut of --range now-[to] . --since 5h is the same as --range now-5h .","title":"Time range"},{"location":"quick-start/#filter","text":"Logs can be filtered server-side. This works for all kjournal commands. You can use the flag --field-selector which supports the same operators as kubectl get does. However on top of that kjournal also supports other operators including > , < or in() . kjournal pods -n mynamespace mypod- --field-selector payload.myLogField = xxx","title":"Filter"},{"location":"api/apiserverconfig.v1alpha1.config.kjournal/","text":"Source API reference Packages: core.kjournal/v1alpha1 core.kjournal/v1alpha1 Resource Types: AuditEvent Event Log AuditEvent AuditEvent Field Description apiVersion string core.kjournal/v1alpha1 kind string AuditEvent - Kubernetes meta/v1.ObjectMeta ObjectMeta is only included to fullfil metav1.Object interface, it will be omitted from any json de and encoding. It is required for storage.ConvertToTable() Refer to the Kubernetes API documentation for the fields of the metadata field. Event k8s.io/apiserver/pkg/apis/audit.Event (Members of Event are embedded into this type.) Event Event Field Description apiVersion string core.kjournal/v1alpha1 kind string Event Event Kubernetes events/v1.Event (Members of Event are embedded into this type.) Log Log Field Description apiVersion string core.kjournal/v1alpha1 kind string Log metadata Kubernetes meta/v1.ObjectMeta Refer to the Kubernetes API documentation for the fields of the metadata field. payload encoding/json.RawMessage ContainerLog Field Description metadata Kubernetes meta/v1.ObjectMeta Refer to the Kubernetes API documentation for the fields of the metadata field. container string pod string payload encoding/json.RawMessage This page was automatically generated with gen-crd-api-reference-docs","title":"Apiserverconfig.v1alpha1.config.kjournal"},{"location":"api/audit.v1/","text":"Source API reference Packages: audit.kjournal/v1 audit.kjournal/v1 Resource Types: ClusterEvent ClusterEvent ClusterEvent Field Description apiVersion string audit.kjournal/v1 kind string ClusterEvent - Kubernetes meta/v1.ObjectMeta ObjectMeta is only included to fullfil metav1.Object interface, it will be omitted from any json de and encoding. It is required for storage.ConvertToTable() Refer to the Kubernetes API documentation for the fields of the metadata field. Event k8s.io/apiserver/pkg/apis/audit/v1.Event (Members of Event are embedded into this type.) Event Event Field Description - Kubernetes meta/v1.ObjectMeta ObjectMeta is only included to fullfil metav1.Object interface, it will be omitted from any json de and encoding. It is required for storage.ConvertToTable() Refer to the Kubernetes API documentation for the fields of the metadata field. Event k8s.io/apiserver/pkg/apis/audit/v1.Event (Members of Event are embedded into this type.) This page was automatically generated with gen-crd-api-reference-docs","title":"Audit.v1"},{"location":"api/config.kjournal.v1alpha1/","text":"Source API reference Packages: config.kjournal/v1alpha1 config.kjournal/v1alpha1 Resource Types: API ( Appears on: APIServerConfig ) Field Description resource string fieldMap map[string][]string dropFields []string filter string backend ApiBackend defaultTimeRange string APIServerConfig APIServerConfig Field Description backend Backend apis []API ApiBackend ( Appears on: API ) Field Description elasticsearch ApiBackendElasticsearch ApiBackendElasticsearch ( Appears on: ApiBackend ) Field Description index string refreshRate Kubernetes meta/v1.Duration timestampFields []string bulkSize int64 Backend ( Appears on: APIServerConfig ) Field Description elasticsearch BackendElasticsearch BackendElasticsearch ( Appears on: Backend ) Field Description url []string tls TLS TLS ( Appears on: BackendElasticsearch ) Field Description allowInsecure bool caCert string serverName string This page was automatically generated with gen-crd-api-reference-docs","title":"Config.kjournal.v1alpha1"},{"location":"api/container.v1beta1/","text":"Source API reference Packages: container.kjournal/v1beta1 container.kjournal/v1beta1 Resource Types: Log Log Log Field Description apiVersion string container.kjournal/v1beta1 kind string Log - Kubernetes meta/v1.ObjectMeta ObjectMeta is only included to fullfil metav1.Object interface, it will be omitted from any json de and encoding. It is required for storage.ConvertToTable() Refer to the Kubernetes API documentation for the fields of the metadata field. metadata LogMetadata container string pod string unstructured encoding/json.RawMessage env encoding/json.RawMessage LogMetadata ( Appears on: Log ) Field Description namespace string creationTimestamp Kubernetes meta/v1.Time This page was automatically generated with gen-crd-api-reference-docs","title":"Container.v1beta1"},{"location":"api/core.kjournal.v1alpha1/","text":"Source API reference Packages: core.kjournal/v1alpha1 core.kjournal/v1alpha1 Resource Types: AuditEvent Event Log AuditEvent AuditEvent Field Description apiVersion string core.kjournal/v1alpha1 kind string AuditEvent - Kubernetes meta/v1.ObjectMeta ObjectMeta is only included to fullfil metav1.Object interface, it will be omitted from any json de and encoding. It is required for storage.ConvertToTable() Refer to the Kubernetes API documentation for the fields of the metadata field. Event k8s.io/apiserver/pkg/apis/audit.Event (Members of Event are embedded into this type.) Event Event Field Description apiVersion string core.kjournal/v1alpha1 kind string Event Event Kubernetes events/v1.Event (Members of Event are embedded into this type.) Log Log Field Description apiVersion string core.kjournal/v1alpha1 kind string Log metadata Kubernetes meta/v1.ObjectMeta Refer to the Kubernetes API documentation for the fields of the metadata field. payload encoding/json.RawMessage ContainerLog Field Description metadata Kubernetes meta/v1.ObjectMeta Refer to the Kubernetes API documentation for the fields of the metadata field. container string pod string payload encoding/json.RawMessage This page was automatically generated with gen-crd-api-reference-docs","title":"Core.kjournal.v1alpha1"},{"location":"api/core.v1alpha1.core.kjournal/","text":"Source API reference Packages: config.kjournal/v1alpha1 config.kjournal/v1alpha1 Resource Types: API ( Appears on: APIServerConfig ) Field Description resource string fieldMap map[string][]string dropFields []string filter map[string]string backend ApiBackend defaultTimeRange string APIServerConfig APIServerConfig Field Description backend Backend apis []API ApiBackend ( Appears on: API ) Field Description elasticsearch ApiBackendElasticsearch ApiBackendElasticsearch ( Appears on: ApiBackend ) Field Description index string refreshRate time.Duration Backend ( Appears on: APIServerConfig ) Field Description elasticsearch BackendElasticsearch BackendElasticsearch ( Appears on: Backend ) Field Description url []string allowInsecureTLS bool cacert string This page was automatically generated with gen-crd-api-reference-docs","title":"Core.v1alpha1.core.kjournal"},{"location":"cli/install/","text":"Install \u00b6 You can install the pre-compiled binary (in several different ways), use Docker or compile from source. Below you can find the steps for each of them. Install the pre-compiled binary \u00b6 Brew Go Bash Docker brew install raffis/kjournal/kjournal go install github.com/raffis/kjournal/cli/cmd@latest curl -sfL https://raw.githubusercontent.com/raffis/kjournal/main/cli/install/kjournal.sh | bash docker pull ghcr.io/raffis/kjournal/cli Specific version \u00b6 Due server compatibility reasons (or any other) you may want to install anoher version rather than the latest. Here version v0.0.1 gets installed. Brew Go Bash Docker brew install raffis/kjournal/kjournal@v0.0.1 go install github.com/raffis/kjournal/cli/cmd@v0.0.1 curl -sfL https://raw.githubusercontent.com/raffis/kjournal/main/cli/install/kjournal.sh | VERSION = 0 .0.1 bash docker pull ghcr.io/raffis/kjournal/cli:v0.0.1 Compatibility with apiserver \u00b6 The kjornal cli gurantees compatibility for three minor versions with the apiserver. The previous minor release, the same and a newer apiserver. That said this guarantees full compatibility, a bigger version gap will likely still work. Example: cli apiserver Fully compatible v1.1.0 v1.0.0 yes v1.1.0 v1.1.0 yes v1.1.0 v1.2.0 yes v1.1.0 v1.3.0 no v1.0.0 v1.2.0 no Note Releases from 0.x do not offer any compatibility guarantees between different versions of the cli and the apiserver. Enable shell completion \u00b6 Bash zsh Fish Fish kjournal completion bash kjournal completion zsh kjournal completion fish kjournal completion powershell Bash Additional Options \u00b6 You can also set the VERSION , OS , and ARCH variables to specify a version instead of using latest. curl -sfL https://raw.githubusercontent.com/raffis/kjournal/main/cli/install/kjournal.sh | VERSION = __VERSION__ bash -s -- check Verifying the artifacts \u00b6 Binaries \u00b6 All artifacts are checksummed and the checksum file is signed with cosign . Download the files you want, and the checksums.txt , checksum.txt.pem and checksums.txt.sig files from the [releases][releases] page: wget https://github.com/raffis/kjournal/releases/download/__VERSION__/checksums.txt wget https://github.com/raffis/kjournal/releases/download/__VERSION__/checksums.txt.sig wget https://github.com/raffis/kjournal/releases/download/__VERSION__/checksums.txt.pem Verify the signature: cosign verify-blob \\ --cert checksums.txt.pem \\ --signature checksums.txt.sig \\ checksums.txt If the signature is valid, you can then verify the SHA256 sums match with the downloaded binary: sha256sum --ignore-missing -c checksums.txt Container images \u00b6 Likewise are the container images signed with cosign . Verify the signatures: cosign verify ghcr.io/raffis/kjournal/cli Info The .pem and .sig files are the image name:tag , replacing / and : with - . Running with Docker \u00b6 You can also use the cli within a Docker container. Example usage: docker run -v ~/.kube:/home/alpine/.kube \\ ghcr.io/raffis/kjournal/cli Compiling from source \u00b6 Here you have two options: If you want to contribute to the project, please follow the steps on our contributing guide . If you just want to build from source for whatever reason, follow these steps: clone: git clone https://github.com/goreleaser/goreleaser cd goreleaser get the dependencies: go mod tidy build: go build -o goreleaser . verify it works: ./goreleaser --version","title":"Install"},{"location":"cli/install/#install","text":"You can install the pre-compiled binary (in several different ways), use Docker or compile from source. Below you can find the steps for each of them.","title":"Install"},{"location":"cli/install/#install-the-pre-compiled-binary","text":"Brew Go Bash Docker brew install raffis/kjournal/kjournal go install github.com/raffis/kjournal/cli/cmd@latest curl -sfL https://raw.githubusercontent.com/raffis/kjournal/main/cli/install/kjournal.sh | bash docker pull ghcr.io/raffis/kjournal/cli","title":"Install the pre-compiled binary"},{"location":"cli/install/#specific-version","text":"Due server compatibility reasons (or any other) you may want to install anoher version rather than the latest. Here version v0.0.1 gets installed. Brew Go Bash Docker brew install raffis/kjournal/kjournal@v0.0.1 go install github.com/raffis/kjournal/cli/cmd@v0.0.1 curl -sfL https://raw.githubusercontent.com/raffis/kjournal/main/cli/install/kjournal.sh | VERSION = 0 .0.1 bash docker pull ghcr.io/raffis/kjournal/cli:v0.0.1","title":"Specific version"},{"location":"cli/install/#compatibility-with-apiserver","text":"The kjornal cli gurantees compatibility for three minor versions with the apiserver. The previous minor release, the same and a newer apiserver. That said this guarantees full compatibility, a bigger version gap will likely still work. Example: cli apiserver Fully compatible v1.1.0 v1.0.0 yes v1.1.0 v1.1.0 yes v1.1.0 v1.2.0 yes v1.1.0 v1.3.0 no v1.0.0 v1.2.0 no Note Releases from 0.x do not offer any compatibility guarantees between different versions of the cli and the apiserver.","title":"Compatibility with apiserver"},{"location":"cli/install/#enable-shell-completion","text":"Bash zsh Fish Fish kjournal completion bash kjournal completion zsh kjournal completion fish kjournal completion powershell","title":"Enable shell completion"},{"location":"cli/install/#bash-additional-options","text":"You can also set the VERSION , OS , and ARCH variables to specify a version instead of using latest. curl -sfL https://raw.githubusercontent.com/raffis/kjournal/main/cli/install/kjournal.sh | VERSION = __VERSION__ bash -s -- check","title":"Bash Additional Options"},{"location":"cli/install/#verifying-the-artifacts","text":"","title":"Verifying the artifacts"},{"location":"cli/install/#binaries","text":"All artifacts are checksummed and the checksum file is signed with cosign . Download the files you want, and the checksums.txt , checksum.txt.pem and checksums.txt.sig files from the [releases][releases] page: wget https://github.com/raffis/kjournal/releases/download/__VERSION__/checksums.txt wget https://github.com/raffis/kjournal/releases/download/__VERSION__/checksums.txt.sig wget https://github.com/raffis/kjournal/releases/download/__VERSION__/checksums.txt.pem Verify the signature: cosign verify-blob \\ --cert checksums.txt.pem \\ --signature checksums.txt.sig \\ checksums.txt If the signature is valid, you can then verify the SHA256 sums match with the downloaded binary: sha256sum --ignore-missing -c checksums.txt","title":"Binaries"},{"location":"cli/install/#container-images","text":"Likewise are the container images signed with cosign . Verify the signatures: cosign verify ghcr.io/raffis/kjournal/cli Info The .pem and .sig files are the image name:tag , replacing / and : with - .","title":"Container images"},{"location":"cli/install/#running-with-docker","text":"You can also use the cli within a Docker container. Example usage: docker run -v ~/.kube:/home/alpine/.kube \\ ghcr.io/raffis/kjournal/cli","title":"Running with Docker"},{"location":"cli/install/#compiling-from-source","text":"Here you have two options: If you want to contribute to the project, please follow the steps on our contributing guide . If you just want to build from source for whatever reason, follow these steps: clone: git clone https://github.com/goreleaser/goreleaser cd goreleaser get the dependencies: go mod tidy build: go build -o goreleaser . verify it works: ./goreleaser --version","title":"Compiling from source"},{"location":"cli/cmdref/kjournal/","text":"kjournal \u00b6 Command line utility for accessing long-term kubernetes logs Synopsis \u00b6 Command line utility for accessing long-term kubernetes logs. Options \u00b6 --as string Username to impersonate for the operation. User could be a regular user or a service account in a namespace. --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --as-uid string UID to impersonate for the operation. --cache-dir string Default cache directory (default \"/home/raffi/.kube/cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use -h, --help help for kjournal --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. -n, --namespace string If present, the namespace scope for this CLI request --server string The address and port of the Kubernetes API server --timeout duration timeout for this operation (default 5m0s) --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --verbose print generated objects SEE ALSO \u00b6 kjournal audit - Get audit events kjournal clusteraudit - Get cluster audit events kjournal diary - Get container logs kjournal version - Print version","title":"Kjournal"},{"location":"cli/cmdref/kjournal/#kjournal","text":"Command line utility for accessing long-term kubernetes logs","title":"kjournal"},{"location":"cli/cmdref/kjournal/#synopsis","text":"Command line utility for accessing long-term kubernetes logs.","title":"Synopsis"},{"location":"cli/cmdref/kjournal/#options","text":"--as string Username to impersonate for the operation. User could be a regular user or a service account in a namespace. --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --as-uid string UID to impersonate for the operation. --cache-dir string Default cache directory (default \"/home/raffi/.kube/cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use -h, --help help for kjournal --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. -n, --namespace string If present, the namespace scope for this CLI request --server string The address and port of the Kubernetes API server --timeout duration timeout for this operation (default 5m0s) --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --verbose print generated objects","title":"Options"},{"location":"cli/cmdref/kjournal/#see-also","text":"kjournal audit - Get audit events kjournal clusteraudit - Get cluster audit events kjournal diary - Get container logs kjournal version - Print version","title":"SEE ALSO"},{"location":"cli/cmdref/kjournal_audit/","text":"kjournal audit \u00b6 Get audit events Synopsis \u00b6 The audit command fetchs events from namespaced resources kjournal audit [flags] Examples \u00b6 # Stream all audit events from the namespace mynamespace kjournal audit -n mynamespace # Stream events from the last 48 hours kjournal audit -n mynamespace --since 48h # Stream events for all deployments kjournal audit -n mynamespace deployments # Stream events for a pod named abc kjournal audit -n mynamespace pods/abc Options \u00b6 --chunk-size int Return large lists in chunks rather than all at once. Pass 0 to disable. This has no impact as long as --no-stream is not set. (default 500) --field-selector string Selector (field query) to filter on, supports '=', '==', '!=', '!=', '>' and '<'. (e.g. --field-selector key1=value1,key2=value2). -h, --help help for audit --no-header skip the header when printing the results --no-stream By default all logs are streamed. This behaviour can be disabled. Be mindful that this can lead to an increased memory usage and no output while logs are beeing gathered -o, --output string Output format. One of: (json, yaml, name, go-template, go-template-file, template, templatefile, jsonpath, jsonpath-as-json, jsonpath-file, custom-columns-file, custom-columns, wide). See custom columns [https://kubernetes.io/docs/reference/kubectl/overview/#custom-columns], golang template [http://golang.org/pkg/text/template/#pkg-overview] and jsonpath template [https://kubernetes.io/docs/reference/kubectl/jsonpath/]. --since --since=now-24h Change the time range from which logs are received. (e.g. --since=now-24h) -w, --watch After dumping all existing logs keep watching for newly added ones Options inherited from parent commands \u00b6 --as string Username to impersonate for the operation. User could be a regular user or a service account in a namespace. --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --as-uid string UID to impersonate for the operation. --cache-dir string Default cache directory (default \"/home/raffi/.kube/cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. -n, --namespace string If present, the namespace scope for this CLI request --server string The address and port of the Kubernetes API server --timeout duration timeout for this operation (default 5m0s) --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --verbose print generated objects SEE ALSO \u00b6 kjournal - Command line utility for accessing long-term kubernetes logs","title":"Kjournal audit"},{"location":"cli/cmdref/kjournal_audit/#kjournal-audit","text":"Get audit events","title":"kjournal audit"},{"location":"cli/cmdref/kjournal_audit/#synopsis","text":"The audit command fetchs events from namespaced resources kjournal audit [flags]","title":"Synopsis"},{"location":"cli/cmdref/kjournal_audit/#examples","text":"# Stream all audit events from the namespace mynamespace kjournal audit -n mynamespace # Stream events from the last 48 hours kjournal audit -n mynamespace --since 48h # Stream events for all deployments kjournal audit -n mynamespace deployments # Stream events for a pod named abc kjournal audit -n mynamespace pods/abc","title":"Examples"},{"location":"cli/cmdref/kjournal_audit/#options","text":"--chunk-size int Return large lists in chunks rather than all at once. Pass 0 to disable. This has no impact as long as --no-stream is not set. (default 500) --field-selector string Selector (field query) to filter on, supports '=', '==', '!=', '!=', '>' and '<'. (e.g. --field-selector key1=value1,key2=value2). -h, --help help for audit --no-header skip the header when printing the results --no-stream By default all logs are streamed. This behaviour can be disabled. Be mindful that this can lead to an increased memory usage and no output while logs are beeing gathered -o, --output string Output format. One of: (json, yaml, name, go-template, go-template-file, template, templatefile, jsonpath, jsonpath-as-json, jsonpath-file, custom-columns-file, custom-columns, wide). See custom columns [https://kubernetes.io/docs/reference/kubectl/overview/#custom-columns], golang template [http://golang.org/pkg/text/template/#pkg-overview] and jsonpath template [https://kubernetes.io/docs/reference/kubectl/jsonpath/]. --since --since=now-24h Change the time range from which logs are received. (e.g. --since=now-24h) -w, --watch After dumping all existing logs keep watching for newly added ones","title":"Options"},{"location":"cli/cmdref/kjournal_audit/#options-inherited-from-parent-commands","text":"--as string Username to impersonate for the operation. User could be a regular user or a service account in a namespace. --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --as-uid string UID to impersonate for the operation. --cache-dir string Default cache directory (default \"/home/raffi/.kube/cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. -n, --namespace string If present, the namespace scope for this CLI request --server string The address and port of the Kubernetes API server --timeout duration timeout for this operation (default 5m0s) --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cli/cmdref/kjournal_audit/#see-also","text":"kjournal - Command line utility for accessing long-term kubernetes logs","title":"SEE ALSO"},{"location":"cli/cmdref/kjournal_clusteraudit/","text":"kjournal clusteraudit \u00b6 Get cluster audit events Synopsis \u00b6 The clusteraudit command fetchs events from alle resources without a namespace kjournal clusteraudit [flags] Examples \u00b6 # Stream cluster events from the last 48h kjournal clusteraudit --since 48h # Stream events for all clusterroles kjournal clusteraudit clusterroles # Stream events for the namespace abc kjournal clusteraudit namespaces/abc Options \u00b6 --chunk-size int Return large lists in chunks rather than all at once. Pass 0 to disable. This has no impact as long as --no-stream is not set. (default 500) --field-selector string Selector (field query) to filter on, supports '=', '==', '!=', '!=', '>' and '<'. (e.g. --field-selector key1=value1,key2=value2). -h, --help help for clusteraudit --no-header skip the header when printing the results --no-stream By default all logs are streamed. This behaviour can be disabled. Be mindful that this can lead to an increased memory usage and no output while logs are beeing gathered -o, --output string Output format. One of: (json, yaml, name, go-template, go-template-file, template, templatefile, jsonpath, jsonpath-as-json, jsonpath-file, custom-columns-file, custom-columns, wide). See custom columns [https://kubernetes.io/docs/reference/kubectl/overview/#custom-columns], golang template [http://golang.org/pkg/text/template/#pkg-overview] and jsonpath template [https://kubernetes.io/docs/reference/kubectl/jsonpath/]. --since --since=now-24h Change the time range from which logs are received. (e.g. --since=now-24h) -w, --watch After dumping all existing logs keep watching for newly added ones Options inherited from parent commands \u00b6 --as string Username to impersonate for the operation. User could be a regular user or a service account in a namespace. --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --as-uid string UID to impersonate for the operation. --cache-dir string Default cache directory (default \"/home/raffi/.kube/cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. -n, --namespace string If present, the namespace scope for this CLI request --server string The address and port of the Kubernetes API server --timeout duration timeout for this operation (default 5m0s) --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --verbose print generated objects SEE ALSO \u00b6 kjournal - Command line utility for accessing long-term kubernetes logs","title":"Kjournal clusteraudit"},{"location":"cli/cmdref/kjournal_clusteraudit/#kjournal-clusteraudit","text":"Get cluster audit events","title":"kjournal clusteraudit"},{"location":"cli/cmdref/kjournal_clusteraudit/#synopsis","text":"The clusteraudit command fetchs events from alle resources without a namespace kjournal clusteraudit [flags]","title":"Synopsis"},{"location":"cli/cmdref/kjournal_clusteraudit/#examples","text":"# Stream cluster events from the last 48h kjournal clusteraudit --since 48h # Stream events for all clusterroles kjournal clusteraudit clusterroles # Stream events for the namespace abc kjournal clusteraudit namespaces/abc","title":"Examples"},{"location":"cli/cmdref/kjournal_clusteraudit/#options","text":"--chunk-size int Return large lists in chunks rather than all at once. Pass 0 to disable. This has no impact as long as --no-stream is not set. (default 500) --field-selector string Selector (field query) to filter on, supports '=', '==', '!=', '!=', '>' and '<'. (e.g. --field-selector key1=value1,key2=value2). -h, --help help for clusteraudit --no-header skip the header when printing the results --no-stream By default all logs are streamed. This behaviour can be disabled. Be mindful that this can lead to an increased memory usage and no output while logs are beeing gathered -o, --output string Output format. One of: (json, yaml, name, go-template, go-template-file, template, templatefile, jsonpath, jsonpath-as-json, jsonpath-file, custom-columns-file, custom-columns, wide). See custom columns [https://kubernetes.io/docs/reference/kubectl/overview/#custom-columns], golang template [http://golang.org/pkg/text/template/#pkg-overview] and jsonpath template [https://kubernetes.io/docs/reference/kubectl/jsonpath/]. --since --since=now-24h Change the time range from which logs are received. (e.g. --since=now-24h) -w, --watch After dumping all existing logs keep watching for newly added ones","title":"Options"},{"location":"cli/cmdref/kjournal_clusteraudit/#options-inherited-from-parent-commands","text":"--as string Username to impersonate for the operation. User could be a regular user or a service account in a namespace. --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --as-uid string UID to impersonate for the operation. --cache-dir string Default cache directory (default \"/home/raffi/.kube/cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. -n, --namespace string If present, the namespace scope for this CLI request --server string The address and port of the Kubernetes API server --timeout duration timeout for this operation (default 5m0s) --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cli/cmdref/kjournal_clusteraudit/#see-also","text":"kjournal - Command line utility for accessing long-term kubernetes logs","title":"SEE ALSO"},{"location":"cli/cmdref/kjournal_diary/","text":"kjournal diary \u00b6 Get container logs Synopsis \u00b6 The diary command prints logs from containers kjournal diary [flags] Examples \u00b6 # Print logs from all pods in the same namespace kjoural diary -n mynamespace Options \u00b6 --chunk-size int Return large lists in chunks rather than all at once. Pass 0 to disable. This has no impact as long as --no-stream is not set. (default 500) -c, --container string Only dump logs from container names matching. (This is the same as --field-selector container=name) --field-selector string Selector (field query) to filter on, supports '=', '==', '!=', '!=', '>' and '<'. (e.g. --field-selector key1=value1,key2=value2). -h, --help help for diary --no-color Don't use colors in the default output --no-stream By default all logs are streamed. This behaviour can be disabled. Be mindful that this can lead to an increased memory usage and no output while logs are beeing gathered -o, --output string Output format. One of: (json, yaml, name, go-template, go-template-file, template, templatefile, jsonpath, jsonpath-as-json, jsonpath-file, custom-columns-file, custom-columns, wide). See custom columns [https://kubernetes.io/docs/reference/kubectl/overview/#custom-columns], golang template [http://golang.org/pkg/text/template/#pkg-overview] and jsonpath template [https://kubernetes.io/docs/reference/kubectl/jsonpath/]. --since --since=now-24h Change the time range from which logs are received. (e.g. --since=now-24h) -t, --timestamp Print creationTime timestamp in the default output. -w, --watch After dumping all existing logs keep watching for newly added ones Options inherited from parent commands \u00b6 --as string Username to impersonate for the operation. User could be a regular user or a service account in a namespace. --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --as-uid string UID to impersonate for the operation. --cache-dir string Default cache directory (default \"/home/raffi/.kube/cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. -n, --namespace string If present, the namespace scope for this CLI request --server string The address and port of the Kubernetes API server --timeout duration timeout for this operation (default 5m0s) --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --verbose print generated objects SEE ALSO \u00b6 kjournal - Command line utility for accessing long-term kubernetes logs","title":"Kjournal diary"},{"location":"cli/cmdref/kjournal_diary/#kjournal-diary","text":"Get container logs","title":"kjournal diary"},{"location":"cli/cmdref/kjournal_diary/#synopsis","text":"The diary command prints logs from containers kjournal diary [flags]","title":"Synopsis"},{"location":"cli/cmdref/kjournal_diary/#examples","text":"# Print logs from all pods in the same namespace kjoural diary -n mynamespace","title":"Examples"},{"location":"cli/cmdref/kjournal_diary/#options","text":"--chunk-size int Return large lists in chunks rather than all at once. Pass 0 to disable. This has no impact as long as --no-stream is not set. (default 500) -c, --container string Only dump logs from container names matching. (This is the same as --field-selector container=name) --field-selector string Selector (field query) to filter on, supports '=', '==', '!=', '!=', '>' and '<'. (e.g. --field-selector key1=value1,key2=value2). -h, --help help for diary --no-color Don't use colors in the default output --no-stream By default all logs are streamed. This behaviour can be disabled. Be mindful that this can lead to an increased memory usage and no output while logs are beeing gathered -o, --output string Output format. One of: (json, yaml, name, go-template, go-template-file, template, templatefile, jsonpath, jsonpath-as-json, jsonpath-file, custom-columns-file, custom-columns, wide). See custom columns [https://kubernetes.io/docs/reference/kubectl/overview/#custom-columns], golang template [http://golang.org/pkg/text/template/#pkg-overview] and jsonpath template [https://kubernetes.io/docs/reference/kubectl/jsonpath/]. --since --since=now-24h Change the time range from which logs are received. (e.g. --since=now-24h) -t, --timestamp Print creationTime timestamp in the default output. -w, --watch After dumping all existing logs keep watching for newly added ones","title":"Options"},{"location":"cli/cmdref/kjournal_diary/#options-inherited-from-parent-commands","text":"--as string Username to impersonate for the operation. User could be a regular user or a service account in a namespace. --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --as-uid string UID to impersonate for the operation. --cache-dir string Default cache directory (default \"/home/raffi/.kube/cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. -n, --namespace string If present, the namespace scope for this CLI request --server string The address and port of the Kubernetes API server --timeout duration timeout for this operation (default 5m0s) --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cli/cmdref/kjournal_diary/#see-also","text":"kjournal - Command line utility for accessing long-term kubernetes logs","title":"SEE ALSO"},{"location":"cli/cmdref/kjournal_version/","text":"kjournal version \u00b6 Print version Synopsis \u00b6 The version command prints the cli version kjournal version [flags] Options \u00b6 -h, --help help for version Options inherited from parent commands \u00b6 --as string Username to impersonate for the operation. User could be a regular user or a service account in a namespace. --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --as-uid string UID to impersonate for the operation. --cache-dir string Default cache directory (default \"/home/raffi/.kube/cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. -n, --namespace string If present, the namespace scope for this CLI request --server string The address and port of the Kubernetes API server --timeout duration timeout for this operation (default 5m0s) --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --verbose print generated objects SEE ALSO \u00b6 kjournal - Command line utility for accessing long-term kubernetes logs","title":"Kjournal version"},{"location":"cli/cmdref/kjournal_version/#kjournal-version","text":"Print version","title":"kjournal version"},{"location":"cli/cmdref/kjournal_version/#synopsis","text":"The version command prints the cli version kjournal version [flags]","title":"Synopsis"},{"location":"cli/cmdref/kjournal_version/#options","text":"-h, --help help for version","title":"Options"},{"location":"cli/cmdref/kjournal_version/#options-inherited-from-parent-commands","text":"--as string Username to impersonate for the operation. User could be a regular user or a service account in a namespace. --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --as-uid string UID to impersonate for the operation. --cache-dir string Default cache directory (default \"/home/raffi/.kube/cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure --kubeconfig string Path to the kubeconfig file to use for CLI requests. -n, --namespace string If present, the namespace scope for this CLI request --server string The address and port of the Kubernetes API server --timeout duration timeout for this operation (default 5m0s) --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cli/cmdref/kjournal_version/#see-also","text":"kjournal - Command line utility for accessing long-term kubernetes logs","title":"SEE ALSO"},{"location":"development/CODE_OF_CONDUCT/","text":"Contributor Covenant Code of Conduct \u00b6 Our Pledge \u00b6 In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation. Our Standards \u00b6 Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Maintainer Responsibilities \u00b6 Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. Scope \u00b6 This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Enforcement \u00b6 Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project maintainer. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership. Attribution \u00b6 This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at http://contributor-covenant.org/version/1/4 .","title":"Contributor Covenant Code of Conduct"},{"location":"development/CODE_OF_CONDUCT/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"development/CODE_OF_CONDUCT/#our-pledge","text":"In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.","title":"Our Pledge"},{"location":"development/CODE_OF_CONDUCT/#our-standards","text":"Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"development/CODE_OF_CONDUCT/#maintainer-responsibilities","text":"Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.","title":"Maintainer Responsibilities"},{"location":"development/CODE_OF_CONDUCT/#scope","text":"This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.","title":"Scope"},{"location":"development/CODE_OF_CONDUCT/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project maintainer. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.","title":"Enforcement"},{"location":"development/CODE_OF_CONDUCT/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at http://contributor-covenant.org/version/1/4 .","title":"Attribution"},{"location":"development/CONTRIBUTING/","text":"Release process \u00b6 Controller release \u00b6 Merge all pr's to master which need to be part of the new release Create pr to master with these changes: Bump kustomization Create CHANGELOG.md entry with release and date Merge pr Push a tag following semantic versioning prefixed by 'v'. Do not create a github release, this is done automatically. Create new branch and add the following changes: Bump chart version Bump charts app version Create pr to master and merge Helm chart change only \u00b6 Create branch with changes Bump chart version Create pr to master and merge","title":"CONTRIBUTING"},{"location":"development/CONTRIBUTING/#release-process","text":"","title":"Release process"},{"location":"development/CONTRIBUTING/#controller-release","text":"Merge all pr's to master which need to be part of the new release Create pr to master with these changes: Bump kustomization Create CHANGELOG.md entry with release and date Merge pr Push a tag following semantic versioning prefixed by 'v'. Do not create a github release, this is done automatically. Create new branch and add the following changes: Bump chart version Bump charts app version Create pr to master and merge","title":"Controller release"},{"location":"development/CONTRIBUTING/#helm-chart-change-only","text":"Create branch with changes Bump chart version Create pr to master and merge","title":"Helm chart change only"},{"location":"prerequisites/audit/","text":"Auditing \u00b6 To store audit logs into the long-term log storage the kube-apiserver needs to be configured to log audits in the first place. See more about auditing in the kubernetes docs. In short the kube-apiserver needs to be started with these flags: --audit-policy-file = /etc/kubernetes/audit-policy.yaml \\ --audit-log-path = /var/log/kubernetes/audit/audit.log This is an example audit policy, a different one may be used. /etc/kubernetes/audit-policy.yaml apiVersion : audit.k8s.io/v1 kind : Policy rules : # The following requests were manually identified as high-volume and low-risk, # so drop them. - level : None users : [ \"system:kube-proxy\" ] verbs : [ \"watch\" ] resources : - group : \"\" # core resources : [ \"endpoints\" , \"services\" , \"services/status\" ] - level : None # Ingress controller reads 'configmaps/ingress-uid' through the unsecured port. # TODO(#46983): Change this to the ingress controller service account. users : [ \"system:unsecured\" ] namespaces : [ \"kube-system\" ] verbs : [ \"get\" ] resources : - group : \"\" # core resources : [ \"configmaps\" ] - level : None users : [ \"kubelet\" ] # legacy kubelet identity verbs : [ \"get\" ] resources : - group : \"\" # core resources : [ \"nodes\" , \"nodes/status\" ] - level : None userGroups : [ \"system:nodes\" ] verbs : [ \"get\" ] resources : - group : \"\" # core resources : [ \"nodes\" , \"nodes/status\" ] - level : None users : - system:kube-controller-manager - system:kube-scheduler - system:serviceaccount:kube-system:endpoint-controller verbs : [ \"get\" , \"update\" ] namespaces : [ \"kube-system\" ] resources : - group : \"\" # core resources : [ \"endpoints\" ] - level : None users : [ \"system:apiserver\" ] verbs : [ \"get\" ] resources : - group : \"\" # core resources : [ \"namespaces\" , \"namespaces/status\" , \"namespaces/finalize\" ] - level : None users : [ \"cluster-autoscaler\" ] verbs : [ \"get\" , \"update\" ] namespaces : [ \"kube-system\" ] resources : - group : \"\" # core resources : [ \"configmaps\" , \"endpoints\" ] # Don't log HPA fetching metrics. - level : None users : - system:kube-controller-manager verbs : [ \"get\" , \"list\" ] resources : - group : \"metrics.k8s.io\" # Don't log these read-only URLs. - level : None nonResourceURLs : - /healthz* - /version - /swagger* # Don't log events requests. - level : None resources : - group : \"\" # core resources : [ \"events\" ] # node and pod status calls from nodes are high-volume and can be large, don't log responses for expected updates from nodes - level : Request users : [ \"kubelet\" , \"system:node-problem-detector\" , \"system:serviceaccount:kube-system:node-problem-detector\" ] verbs : [ \"update\" , \"patch\" ] resources : - group : \"\" # core resources : [ \"nodes/status\" , \"pods/status\" ] omitStages : - \"RequestReceived\" - level : Request userGroups : [ \"system:nodes\" ] verbs : [ \"update\" , \"patch\" ] resources : - group : \"\" # core resources : [ \"nodes/status\" , \"pods/status\" ] omitStages : - \"RequestReceived\" # deletecollection calls can be large, don't log responses for expected namespace deletions - level : Request users : [ \"system:serviceaccount:kube-system:namespace-controller\" ] verbs : [ \"deletecollection\" ] omitStages : - \"RequestReceived\" # Secrets, ConfigMaps, and TokenReviews can contain sensitive & binary data, # so only log at the Metadata level. - level : Metadata resources : - group : \"\" # core resources : [ \"secrets\" , \"configmaps\" ] - group : authentication.k8s.io resources : [ \"tokenreviews\" ] omitStages : - \"RequestReceived\" # Get repsonses can be large; skip them. - level : Request verbs : [ \"get\" , \"list\" , \"watch\" ] resources : - group : \"\" # core - group : \"admissionregistration.k8s.io\" - group : \"apiextensions.k8s.io\" - group : \"apiregistration.k8s.io\" - group : \"apps\" - group : \"authentication.k8s.io\" - group : \"authorization.k8s.io\" - group : \"autoscaling\" - group : \"batch\" - group : \"certificates.k8s.io\" - group : \"extensions\" - group : \"metrics.k8s.io\" - group : \"networking.k8s.io\" - group : \"node.k8s.io\" - group : \"policy\" - group : \"rbac.authorization.k8s.io\" - group : \"scheduling.k8s.io\" - group : \"settings.k8s.io\" - group : \"storage.k8s.io\" omitStages : - \"RequestReceived\" # Default level for known APIs - level : RequestResponse resources : - group : \"\" # core - group : \"admissionregistration.k8s.io\" - group : \"apiextensions.k8s.io\" - group : \"apiregistration.k8s.io\" - group : \"apps\" - group : \"authentication.k8s.io\" - group : \"authorization.k8s.io\" - group : \"autoscaling\" - group : \"batch\" - group : \"certificates.k8s.io\" - group : \"extensions\" - group : \"metrics.k8s.io\" - group : \"networking.k8s.io\" - group : \"node.k8s.io\" - group : \"policy\" - group : \"rbac.authorization.k8s.io\" - group : \"scheduling.k8s.io\" - group : \"settings.k8s.io\" - group : \"storage.k8s.io\" omitStages : - \"RequestReceived\" # Default level for all other requests. - level : Metadata omitStages : - \"RequestReceived\" KOPS \u00b6 With kops auditing can be enabled on the cluster specification. Read more about it here . kind \u00b6 Auditing can easily be configured within a kind cluster config .","title":"Auditing"},{"location":"prerequisites/audit/#auditing","text":"To store audit logs into the long-term log storage the kube-apiserver needs to be configured to log audits in the first place. See more about auditing in the kubernetes docs. In short the kube-apiserver needs to be started with these flags: --audit-policy-file = /etc/kubernetes/audit-policy.yaml \\ --audit-log-path = /var/log/kubernetes/audit/audit.log This is an example audit policy, a different one may be used. /etc/kubernetes/audit-policy.yaml apiVersion : audit.k8s.io/v1 kind : Policy rules : # The following requests were manually identified as high-volume and low-risk, # so drop them. - level : None users : [ \"system:kube-proxy\" ] verbs : [ \"watch\" ] resources : - group : \"\" # core resources : [ \"endpoints\" , \"services\" , \"services/status\" ] - level : None # Ingress controller reads 'configmaps/ingress-uid' through the unsecured port. # TODO(#46983): Change this to the ingress controller service account. users : [ \"system:unsecured\" ] namespaces : [ \"kube-system\" ] verbs : [ \"get\" ] resources : - group : \"\" # core resources : [ \"configmaps\" ] - level : None users : [ \"kubelet\" ] # legacy kubelet identity verbs : [ \"get\" ] resources : - group : \"\" # core resources : [ \"nodes\" , \"nodes/status\" ] - level : None userGroups : [ \"system:nodes\" ] verbs : [ \"get\" ] resources : - group : \"\" # core resources : [ \"nodes\" , \"nodes/status\" ] - level : None users : - system:kube-controller-manager - system:kube-scheduler - system:serviceaccount:kube-system:endpoint-controller verbs : [ \"get\" , \"update\" ] namespaces : [ \"kube-system\" ] resources : - group : \"\" # core resources : [ \"endpoints\" ] - level : None users : [ \"system:apiserver\" ] verbs : [ \"get\" ] resources : - group : \"\" # core resources : [ \"namespaces\" , \"namespaces/status\" , \"namespaces/finalize\" ] - level : None users : [ \"cluster-autoscaler\" ] verbs : [ \"get\" , \"update\" ] namespaces : [ \"kube-system\" ] resources : - group : \"\" # core resources : [ \"configmaps\" , \"endpoints\" ] # Don't log HPA fetching metrics. - level : None users : - system:kube-controller-manager verbs : [ \"get\" , \"list\" ] resources : - group : \"metrics.k8s.io\" # Don't log these read-only URLs. - level : None nonResourceURLs : - /healthz* - /version - /swagger* # Don't log events requests. - level : None resources : - group : \"\" # core resources : [ \"events\" ] # node and pod status calls from nodes are high-volume and can be large, don't log responses for expected updates from nodes - level : Request users : [ \"kubelet\" , \"system:node-problem-detector\" , \"system:serviceaccount:kube-system:node-problem-detector\" ] verbs : [ \"update\" , \"patch\" ] resources : - group : \"\" # core resources : [ \"nodes/status\" , \"pods/status\" ] omitStages : - \"RequestReceived\" - level : Request userGroups : [ \"system:nodes\" ] verbs : [ \"update\" , \"patch\" ] resources : - group : \"\" # core resources : [ \"nodes/status\" , \"pods/status\" ] omitStages : - \"RequestReceived\" # deletecollection calls can be large, don't log responses for expected namespace deletions - level : Request users : [ \"system:serviceaccount:kube-system:namespace-controller\" ] verbs : [ \"deletecollection\" ] omitStages : - \"RequestReceived\" # Secrets, ConfigMaps, and TokenReviews can contain sensitive & binary data, # so only log at the Metadata level. - level : Metadata resources : - group : \"\" # core resources : [ \"secrets\" , \"configmaps\" ] - group : authentication.k8s.io resources : [ \"tokenreviews\" ] omitStages : - \"RequestReceived\" # Get repsonses can be large; skip them. - level : Request verbs : [ \"get\" , \"list\" , \"watch\" ] resources : - group : \"\" # core - group : \"admissionregistration.k8s.io\" - group : \"apiextensions.k8s.io\" - group : \"apiregistration.k8s.io\" - group : \"apps\" - group : \"authentication.k8s.io\" - group : \"authorization.k8s.io\" - group : \"autoscaling\" - group : \"batch\" - group : \"certificates.k8s.io\" - group : \"extensions\" - group : \"metrics.k8s.io\" - group : \"networking.k8s.io\" - group : \"node.k8s.io\" - group : \"policy\" - group : \"rbac.authorization.k8s.io\" - group : \"scheduling.k8s.io\" - group : \"settings.k8s.io\" - group : \"storage.k8s.io\" omitStages : - \"RequestReceived\" # Default level for known APIs - level : RequestResponse resources : - group : \"\" # core - group : \"admissionregistration.k8s.io\" - group : \"apiextensions.k8s.io\" - group : \"apiregistration.k8s.io\" - group : \"apps\" - group : \"authentication.k8s.io\" - group : \"authorization.k8s.io\" - group : \"autoscaling\" - group : \"batch\" - group : \"certificates.k8s.io\" - group : \"extensions\" - group : \"metrics.k8s.io\" - group : \"networking.k8s.io\" - group : \"node.k8s.io\" - group : \"policy\" - group : \"rbac.authorization.k8s.io\" - group : \"scheduling.k8s.io\" - group : \"settings.k8s.io\" - group : \"storage.k8s.io\" omitStages : - \"RequestReceived\" # Default level for all other requests. - level : Metadata omitStages : - \"RequestReceived\"","title":"Auditing"},{"location":"prerequisites/audit/#kops","text":"With kops auditing can be enabled on the cluster specification. Read more about it here .","title":"KOPS"},{"location":"prerequisites/audit/#kind","text":"Auditing can easily be configured within a kind cluster config .","title":"kind"},{"location":"prerequisites/event-exporter/","text":"Events \u00b6 To persist the kubernetes events an exporter is needed which watches the kubernetes events and exports them into a configured sink. opsgenie/kubernetes-event-exporter is a good tool for this job. Note The original project is archived, resmoio/kubernetes-event-exporter is a maintained fork. The following installs the exporter for elasticsearch, however there are various other sinks supported. kubectl create ns logging helm repo add bitnami https://charts.bitnami.com/bitnami helm upgrade kubernetes-event-exporter bitnami/kubernetes-event-exporter --install -n logging -f values.yaml values.yaml config : logLevel : info logFormat : pretty receivers : - name : \"dump\" elasticsearch : hosts : - http://elasticsearch-master:9200 index : k8sevents # Ca be used optionally for time based indices, accepts Go time formatting directives indexFormat : \"k8sevents-{2006-01-02}\" useEventID : true deDot : false route : routes : - match : - receiver : \"dump\"","title":"Events"},{"location":"prerequisites/event-exporter/#events","text":"To persist the kubernetes events an exporter is needed which watches the kubernetes events and exports them into a configured sink. opsgenie/kubernetes-event-exporter is a good tool for this job. Note The original project is archived, resmoio/kubernetes-event-exporter is a maintained fork. The following installs the exporter for elasticsearch, however there are various other sinks supported. kubectl create ns logging helm repo add bitnami https://charts.bitnami.com/bitnami helm upgrade kubernetes-event-exporter bitnami/kubernetes-event-exporter --install -n logging -f values.yaml values.yaml config : logLevel : info logFormat : pretty receivers : - name : \"dump\" elasticsearch : hosts : - http://elasticsearch-master:9200 index : k8sevents # Ca be used optionally for time based indices, accepts Go time formatting directives indexFormat : \"k8sevents-{2006-01-02}\" useEventID : true deDot : false route : routes : - match : - receiver : \"dump\"","title":"Events"},{"location":"prerequisites/ship/","text":"Ship container & audit logs \u00b6 Both audit and container logs need to be persisted in the longterm log storage. For this a component is required which tails these logs on the kubernetes nodes and pushes them to the storage. There are various tools out there doing exactly this. Namely fluent-bit , filebeat or fluent . Important kjournal needs kubernetes metadata for the container logs from the longterm storage. Both fluent-bit and filebeat provide a kubernetes filter to attach that data to all container logs. fluent-bit \u00b6 fluent-bit usually is installed as a DaemonSet. Following an example configuration which ships both audit events and container logs to an elasticsearch cluster. [INPUT] Name tail Tag kube.* Path /var/log/containers/*.log Parser cri DB /var/log/flb_kube-fwd.db Refresh_Interval 5 Skip_Long_Lines On Mem_Buf_Limit 5MB Read_from_Head True [INPUT] Name tail Path /var/log/kube-apiserver-audit.log Parser docker DB /var/log/audit-fwd.db Tag audit.* Refresh_Interval 5 Mem_Buf_Limit 35MB Buffer_Chunk_Size 2MB Buffer_Max_Size 10MB Skip_Long_Lines On Key kubernetes-audit Read_from_Head True # Stores container logs in logstash-* indexes. [OUTPUT] Name es Match kube.* Host elasticsearch-master Port 9200 Time_Key @es_ts Logstash_Format On Replace_Dots On Type _doc # Stores audit events in a separate index pattern k8saudit-* [OUTPUT] Name es Match audit.* Host elasticsearch-master Port 9200 Logstash_Format On Replace_Dots On Logstash_Prefix k8saudit Type _doc [SERVICE] Flush 1 Daemon Off Log_Level info Parsers_File parsers.conf HTTP_Server On HTTP_Listen 0.0.0.0 HTTP_Port 2020 [FILTER] Name parser Match kube.* Key_Name message Parser docker [FILTER] Name kubernetes Match kube.* Merge_Log On Keep_Log Off K8S-Logging.Parser On K8S-Logging.Exclude On","title":"Ship container & audit logs"},{"location":"prerequisites/ship/#ship-container-audit-logs","text":"Both audit and container logs need to be persisted in the longterm log storage. For this a component is required which tails these logs on the kubernetes nodes and pushes them to the storage. There are various tools out there doing exactly this. Namely fluent-bit , filebeat or fluent . Important kjournal needs kubernetes metadata for the container logs from the longterm storage. Both fluent-bit and filebeat provide a kubernetes filter to attach that data to all container logs.","title":"Ship container &amp; audit logs"},{"location":"prerequisites/ship/#fluent-bit","text":"fluent-bit usually is installed as a DaemonSet. Following an example configuration which ships both audit events and container logs to an elasticsearch cluster. [INPUT] Name tail Tag kube.* Path /var/log/containers/*.log Parser cri DB /var/log/flb_kube-fwd.db Refresh_Interval 5 Skip_Long_Lines On Mem_Buf_Limit 5MB Read_from_Head True [INPUT] Name tail Path /var/log/kube-apiserver-audit.log Parser docker DB /var/log/audit-fwd.db Tag audit.* Refresh_Interval 5 Mem_Buf_Limit 35MB Buffer_Chunk_Size 2MB Buffer_Max_Size 10MB Skip_Long_Lines On Key kubernetes-audit Read_from_Head True # Stores container logs in logstash-* indexes. [OUTPUT] Name es Match kube.* Host elasticsearch-master Port 9200 Time_Key @es_ts Logstash_Format On Replace_Dots On Type _doc # Stores audit events in a separate index pattern k8saudit-* [OUTPUT] Name es Match audit.* Host elasticsearch-master Port 9200 Logstash_Format On Replace_Dots On Logstash_Prefix k8saudit Type _doc [SERVICE] Flush 1 Daemon Off Log_Level info Parsers_File parsers.conf HTTP_Server On HTTP_Listen 0.0.0.0 HTTP_Port 2020 [FILTER] Name parser Match kube.* Key_Name message Parser docker [FILTER] Name kubernetes Match kube.* Merge_Log On Keep_Log Off K8S-Logging.Parser On K8S-Logging.Exclude On","title":"fluent-bit"},{"location":"server/config/","text":"Configuration \u00b6 The apiserver needs to be configured with a backend storage where your logs are persisted. Example config for elasticsearch: v1alpha1 apiVersion : config.kjournal/v1alpha1 kind : APIServerConfig backend : elasticsearch : url : - http://elasticsearch-master:9200 apis : - resource : containerlogs backend : elasticsearch : index : container-* - resource : events backend : elasticsearch : index : k8sevents-* - resource : auditevents backend : elasticsearch : index : k8saudit-* - resource : logs fieldMap : metadata.creationTimestamp : [ \"@timestamp\" ] payload : [ \".\" ] backend : elasticsearch : index : \"*\" Apis \u00b6 Each resource can be customized including how your long-term storage logs are mapped to the kjournal API. Field maps \u00b6 A field map can be used to map a kjournal api to the long term storage representation of messages. There might be multiple reasons you may need do define a fieldmap for kjournal rather than changing the log structure at ingest time. For instance to support backwards compatibility or there might be other services using the current log structure. The field map basicaly consists of one or more field maps: fieldMap : kjournal-api-field : [ source-field-1 , source-field-2 ] ... Note You don't need to define fields which are already at the correct path for the kjournal API. Note You can define one or multiple source fields. The first source field found from the storage will be mapped to the output document. The fields after are ignored. resource : containerlogs fieldMap : metadata.namespace : [ kubernetes.namespace_name ] The above mapping will decode the stored log into a containerlogs.v1alpha1.core.kournal . metadata.namespace will be mapped to the storage field kubernetes.namespace_name . Note You can use . which represents the object root. For example payload: \".\" means that the entire stored object will be mapped to the payload field and not just a specific path. Remove fields \u00b6 Using drop fields allows to remove specific paths from an object. This is useful if you want to remove a specific field from a sub object which was mapped previously. Note : Drop fields happens after the field mapping. Static filters \u00b6 It may be useful to have static filters appended to all storage queries. Meaning you preselect the objects returned from the backing storage. Note You may use static filter to prefilter objects if you have multiple kubernetes clusters logging to the same backing storage and want kjournal on each cluster to only fetch its own clusters logs.","title":"Configuration"},{"location":"server/config/#configuration","text":"The apiserver needs to be configured with a backend storage where your logs are persisted. Example config for elasticsearch: v1alpha1 apiVersion : config.kjournal/v1alpha1 kind : APIServerConfig backend : elasticsearch : url : - http://elasticsearch-master:9200 apis : - resource : containerlogs backend : elasticsearch : index : container-* - resource : events backend : elasticsearch : index : k8sevents-* - resource : auditevents backend : elasticsearch : index : k8saudit-* - resource : logs fieldMap : metadata.creationTimestamp : [ \"@timestamp\" ] payload : [ \".\" ] backend : elasticsearch : index : \"*\"","title":"Configuration"},{"location":"server/config/#apis","text":"Each resource can be customized including how your long-term storage logs are mapped to the kjournal API.","title":"Apis"},{"location":"server/config/#field-maps","text":"A field map can be used to map a kjournal api to the long term storage representation of messages. There might be multiple reasons you may need do define a fieldmap for kjournal rather than changing the log structure at ingest time. For instance to support backwards compatibility or there might be other services using the current log structure. The field map basicaly consists of one or more field maps: fieldMap : kjournal-api-field : [ source-field-1 , source-field-2 ] ... Note You don't need to define fields which are already at the correct path for the kjournal API. Note You can define one or multiple source fields. The first source field found from the storage will be mapped to the output document. The fields after are ignored. resource : containerlogs fieldMap : metadata.namespace : [ kubernetes.namespace_name ] The above mapping will decode the stored log into a containerlogs.v1alpha1.core.kournal . metadata.namespace will be mapped to the storage field kubernetes.namespace_name . Note You can use . which represents the object root. For example payload: \".\" means that the entire stored object will be mapped to the payload field and not just a specific path.","title":"Field maps"},{"location":"server/config/#remove-fields","text":"Using drop fields allows to remove specific paths from an object. This is useful if you want to remove a specific field from a sub object which was mapped previously. Note : Drop fields happens after the field mapping.","title":"Remove fields"},{"location":"server/config/#static-filters","text":"It may be useful to have static filters appended to all storage queries. Meaning you preselect the objects returned from the backing storage. Note You may use static filter to prefilter objects if you have multiple kubernetes clusters logging to the same backing storage and want kjournal on each cluster to only fetch its own clusters logs.","title":"Static filters"},{"location":"server/install/","text":"Install \u00b6 The kjournal apiserver can be deployed using you favourite continous delivery utitlities or you may build and deploy from the source code. Below you can find the steps for each of them. Install the pre-compiled apiserver \u00b6 A backing storage needs to be confgured in order to tell kjournal from where it can get the data. This is the longterm storage your log shippers will send data to. All installation method offer a couple of preconfigured installation templates to get started. Visit the config page for more information regarding the kjournal apiserver config. The default behaviour is elasticsearch as backing storage and it expects kjournal structured documents. kjournal Kustomize Helm kjournal install -n kjournal-system --with-config-template = elasticsearch-kjournal-structured cat <<EOT >> kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - github.com/raffis/kjournal//config/default components: - github.com/raffis/kjournal//config/components/config-templates/elasticsearch-kjournal-structured EOT && kustomize build | kubectl apply -f - helm upgrade kjournal --install oci://ghcr.io/raffis/charts/kjournal --set apiserverConfig.templateName = elasticsearch-kjournal-structured You may find addtional documentation regarding support chart values in the chart documentation here . Warning It is recommended to enable certmanager support on any production cluster. See bellow. Configuration templates \u00b6 Template name Description elasticsearch-kjournal-structured Configures the apiserver for an elasticsearch backend. The docuements are expected to be directly compatible with the kjournal api specification. elasticsearch-fluentbit-simple Configures the apiserver for an elasticsearch backend. The fields are mapped to to a document structure which is usually created by the fluent-bit kubernetes plugin without any special configuration. elasticsearch-filebeat-simple Configures the apiserver for an elasticsearch backend. The fields are mapped to to a document structure which is usually created by the filebeat kubernetes plugin without any special configuration. Install a specific version of the pre-compiled apiserver \u00b6 kjournal Kustomize Helm kjournal install -n kjournal-system --version 0 .0.1 kustomize build github.com/raffis/kjournal?ref = v0.0.1//config/default | kubectl apply -f - helm upgrade kjournal --install oci://ghcr.io/raffis/charts/kjournal --version 0 .0.1 Certmanager support \u00b6 It is recommended to enable certmanger support for setting up a trusted certificate between the kubernetes apiserver and the kjournal apiserver. By default the kuberntes apiserver trusts kjournal without validating the certificate. kjournal Helm Kustomize kjournal install -n kjournal-system --with-certmanager helm upgrade kjournal --install oci://ghcr.io/raffis/charts/kjournal --set certmanager.enabled = true cat <<EOT >> kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - github.com/raffis/kjournal//config/default components: - github.com/raffis/kjournal//config/components/certmanager EOT && kustomize build | kubectl apply -f - Prometheus support \u00b6 kjournal has support for the prometheus-operator or using prometheus scraping via annotations. kjournal Helm Kustomize kjournal install -n kjournal-system --with-prometheus = operator/annotations helm upgrade kjournal --install oci://ghcr.io/raffis/charts/kjournal --set serviceMonitor.enabled = true cat <<EOT >> kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - github.com/raffis/kjournal//config/default components: - github.com/raffis/kjournal//config/base/components/prometheus EOT && kustomize build | kubectl apply -f - Verifying the artifacts \u00b6 Binaries \u00b6 All artifacts are checksummed and the checksum file is signed with cosign . Download the files you want, and the checksums.txt , checksum.txt.pem and checksums.txt.sig files from the [releases][releases] page: wget https://github.com/raffis/kjournal/releases/download/__VERSION__/checksums.txt wget https://github.com/raffis/kjournal/releases/download/__VERSION__/checksums.txt.sig wget https://github.com/raffis/kjournal/releases/download/__VERSION__/checksums.txt.pem Verify the signature: cosign verify-blob \\ --cert checksums.txt.pem \\ --signature checksums.txt.sig \\ checksums.txt If the signature is valid, you can then verify the SHA256 sums match with the downloaded binary: sha256sum --ignore-missing -c checksums.txt Container images \u00b6 Likewise are the container images signed with cosign . Verify the signatures: cosign verify ghcr.io/raffis/kjournal/apiserver Info The .pem and .sig files are the image name:tag , replacing / and : with - . Compile and install from source \u00b6 Here you have two options: If you want to contribute to the project, please follow the steps on our contributing guide . If you just want to build from source for whatever reason, follow these steps: clone: git clone https://github.com/raffis/kjournal cd kjournal build image: make docker-build deploy: make deploy Note make deploy uses kustomize under the hood to apply the overlay config/default with the just built image.","title":"Install"},{"location":"server/install/#install","text":"The kjournal apiserver can be deployed using you favourite continous delivery utitlities or you may build and deploy from the source code. Below you can find the steps for each of them.","title":"Install"},{"location":"server/install/#install-the-pre-compiled-apiserver","text":"A backing storage needs to be confgured in order to tell kjournal from where it can get the data. This is the longterm storage your log shippers will send data to. All installation method offer a couple of preconfigured installation templates to get started. Visit the config page for more information regarding the kjournal apiserver config. The default behaviour is elasticsearch as backing storage and it expects kjournal structured documents. kjournal Kustomize Helm kjournal install -n kjournal-system --with-config-template = elasticsearch-kjournal-structured cat <<EOT >> kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - github.com/raffis/kjournal//config/default components: - github.com/raffis/kjournal//config/components/config-templates/elasticsearch-kjournal-structured EOT && kustomize build | kubectl apply -f - helm upgrade kjournal --install oci://ghcr.io/raffis/charts/kjournal --set apiserverConfig.templateName = elasticsearch-kjournal-structured You may find addtional documentation regarding support chart values in the chart documentation here . Warning It is recommended to enable certmanager support on any production cluster. See bellow.","title":"Install the pre-compiled apiserver"},{"location":"server/install/#configuration-templates","text":"Template name Description elasticsearch-kjournal-structured Configures the apiserver for an elasticsearch backend. The docuements are expected to be directly compatible with the kjournal api specification. elasticsearch-fluentbit-simple Configures the apiserver for an elasticsearch backend. The fields are mapped to to a document structure which is usually created by the fluent-bit kubernetes plugin without any special configuration. elasticsearch-filebeat-simple Configures the apiserver for an elasticsearch backend. The fields are mapped to to a document structure which is usually created by the filebeat kubernetes plugin without any special configuration.","title":"Configuration templates"},{"location":"server/install/#install-a-specific-version-of-the-pre-compiled-apiserver","text":"kjournal Kustomize Helm kjournal install -n kjournal-system --version 0 .0.1 kustomize build github.com/raffis/kjournal?ref = v0.0.1//config/default | kubectl apply -f - helm upgrade kjournal --install oci://ghcr.io/raffis/charts/kjournal --version 0 .0.1","title":"Install a specific version of the pre-compiled apiserver"},{"location":"server/install/#certmanager-support","text":"It is recommended to enable certmanger support for setting up a trusted certificate between the kubernetes apiserver and the kjournal apiserver. By default the kuberntes apiserver trusts kjournal without validating the certificate. kjournal Helm Kustomize kjournal install -n kjournal-system --with-certmanager helm upgrade kjournal --install oci://ghcr.io/raffis/charts/kjournal --set certmanager.enabled = true cat <<EOT >> kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - github.com/raffis/kjournal//config/default components: - github.com/raffis/kjournal//config/components/certmanager EOT && kustomize build | kubectl apply -f -","title":"Certmanager support"},{"location":"server/install/#prometheus-support","text":"kjournal has support for the prometheus-operator or using prometheus scraping via annotations. kjournal Helm Kustomize kjournal install -n kjournal-system --with-prometheus = operator/annotations helm upgrade kjournal --install oci://ghcr.io/raffis/charts/kjournal --set serviceMonitor.enabled = true cat <<EOT >> kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - github.com/raffis/kjournal//config/default components: - github.com/raffis/kjournal//config/base/components/prometheus EOT && kustomize build | kubectl apply -f -","title":"Prometheus support"},{"location":"server/install/#verifying-the-artifacts","text":"","title":"Verifying the artifacts"},{"location":"server/install/#binaries","text":"All artifacts are checksummed and the checksum file is signed with cosign . Download the files you want, and the checksums.txt , checksum.txt.pem and checksums.txt.sig files from the [releases][releases] page: wget https://github.com/raffis/kjournal/releases/download/__VERSION__/checksums.txt wget https://github.com/raffis/kjournal/releases/download/__VERSION__/checksums.txt.sig wget https://github.com/raffis/kjournal/releases/download/__VERSION__/checksums.txt.pem Verify the signature: cosign verify-blob \\ --cert checksums.txt.pem \\ --signature checksums.txt.sig \\ checksums.txt If the signature is valid, you can then verify the SHA256 sums match with the downloaded binary: sha256sum --ignore-missing -c checksums.txt","title":"Binaries"},{"location":"server/install/#container-images","text":"Likewise are the container images signed with cosign . Verify the signatures: cosign verify ghcr.io/raffis/kjournal/apiserver Info The .pem and .sig files are the image name:tag , replacing / and : with - .","title":"Container images"},{"location":"server/install/#compile-and-install-from-source","text":"Here you have two options: If you want to contribute to the project, please follow the steps on our contributing guide . If you just want to build from source for whatever reason, follow these steps: clone: git clone https://github.com/raffis/kjournal cd kjournal build image: make docker-build deploy: make deploy Note make deploy uses kustomize under the hood to apply the overlay config/default with the just built image.","title":"Compile and install from source"},{"location":"server/uninstall/","text":"Uninstall \u00b6 Kjournal can easily be removed using the same utilities as it was installed. Uninstall apiserver \u00b6 kjournal Kustomize Helm kjournal uninstall -n kjournal-system kustomize build github.com/raffis/kjournal//config/default | kubectl remove -f - helm delete kjournal","title":"Uninstall"},{"location":"server/uninstall/#uninstall","text":"Kjournal can easily be removed using the same utilities as it was installed.","title":"Uninstall"},{"location":"server/uninstall/#uninstall-apiserver","text":"kjournal Kustomize Helm kjournal uninstall -n kjournal-system kustomize build github.com/raffis/kjournal//config/default | kubectl remove -f - helm delete kjournal","title":"Uninstall apiserver"},{"location":"server/cmdref/_completion/","text":"completion \u00b6 Generate the autocompletion script for the specified shell Synopsis \u00b6 Generate the autocompletion script for for the specified shell. See each sub-command's help for details on how to use the generated script. Options \u00b6 -h, --help help for completion SEE ALSO \u00b6 - kjournal-apiserver completion bash - Generate the autocompletion script for bash completion fish - Generate the autocompletion script for fish completion powershell - Generate the autocompletion script for powershell completion zsh - Generate the autocompletion script for zsh","title":" completion"},{"location":"server/cmdref/_completion/#completion","text":"Generate the autocompletion script for the specified shell","title":"completion"},{"location":"server/cmdref/_completion/#synopsis","text":"Generate the autocompletion script for for the specified shell. See each sub-command's help for details on how to use the generated script.","title":"Synopsis"},{"location":"server/cmdref/_completion/#options","text":"-h, --help help for completion","title":"Options"},{"location":"server/cmdref/_completion/#see-also","text":"- kjournal-apiserver completion bash - Generate the autocompletion script for bash completion fish - Generate the autocompletion script for fish completion powershell - Generate the autocompletion script for powershell completion zsh - Generate the autocompletion script for zsh","title":"SEE ALSO"},{"location":"server/cmdref/_completion_bash/","text":"completion bash \u00b6 Generate the autocompletion script for bash Synopsis \u00b6 Generate the autocompletion script for the bash shell. This script depends on the 'bash-completion' package. If it is not installed already, you can install it via your OS's package manager. To load completions in your current shell session: source <( completion bash) To load completions for every new session, execute once: Linux: \u00b6 completion bash > /etc/bash_completion.d/ macOS: \u00b6 completion bash > $(brew --prefix)/etc/bash_completion.d/ You will need to start a new shell for this setup to take effect. completion bash Options \u00b6 -h, --help help for bash --no-descriptions disable completion descriptions SEE ALSO \u00b6 completion - Generate the autocompletion script for the specified shell","title":" completion bash"},{"location":"server/cmdref/_completion_bash/#completion-bash","text":"Generate the autocompletion script for bash","title":"completion bash"},{"location":"server/cmdref/_completion_bash/#synopsis","text":"Generate the autocompletion script for the bash shell. This script depends on the 'bash-completion' package. If it is not installed already, you can install it via your OS's package manager. To load completions in your current shell session: source <( completion bash) To load completions for every new session, execute once:","title":"Synopsis"},{"location":"server/cmdref/_completion_bash/#linux","text":"completion bash > /etc/bash_completion.d/","title":"Linux:"},{"location":"server/cmdref/_completion_bash/#macos","text":"completion bash > $(brew --prefix)/etc/bash_completion.d/ You will need to start a new shell for this setup to take effect. completion bash","title":"macOS:"},{"location":"server/cmdref/_completion_bash/#options","text":"-h, --help help for bash --no-descriptions disable completion descriptions","title":"Options"},{"location":"server/cmdref/_completion_bash/#see-also","text":"completion - Generate the autocompletion script for the specified shell","title":"SEE ALSO"},{"location":"server/cmdref/_completion_fish/","text":"completion fish \u00b6 Generate the autocompletion script for fish Synopsis \u00b6 Generate the autocompletion script for the fish shell. To load completions in your current shell session: completion fish | source To load completions for every new session, execute once: completion fish > ~/.config/fish/completions/.fish You will need to start a new shell for this setup to take effect. completion fish [flags] Options \u00b6 -h, --help help for fish --no-descriptions disable completion descriptions SEE ALSO \u00b6 completion - Generate the autocompletion script for the specified shell","title":" completion fish"},{"location":"server/cmdref/_completion_fish/#completion-fish","text":"Generate the autocompletion script for fish","title":"completion fish"},{"location":"server/cmdref/_completion_fish/#synopsis","text":"Generate the autocompletion script for the fish shell. To load completions in your current shell session: completion fish | source To load completions for every new session, execute once: completion fish > ~/.config/fish/completions/.fish You will need to start a new shell for this setup to take effect. completion fish [flags]","title":"Synopsis"},{"location":"server/cmdref/_completion_fish/#options","text":"-h, --help help for fish --no-descriptions disable completion descriptions","title":"Options"},{"location":"server/cmdref/_completion_fish/#see-also","text":"completion - Generate the autocompletion script for the specified shell","title":"SEE ALSO"},{"location":"server/cmdref/_completion_powershell/","text":"completion powershell \u00b6 Generate the autocompletion script for powershell Synopsis \u00b6 Generate the autocompletion script for powershell. To load completions in your current shell session: completion powershell | Out-String | Invoke-Expression To load completions for every new session, add the output of the above command to your powershell profile. completion powershell [flags] Options \u00b6 -h, --help help for powershell --no-descriptions disable completion descriptions SEE ALSO \u00b6 completion - Generate the autocompletion script for the specified shell","title":" completion powershell"},{"location":"server/cmdref/_completion_powershell/#completion-powershell","text":"Generate the autocompletion script for powershell","title":"completion powershell"},{"location":"server/cmdref/_completion_powershell/#synopsis","text":"Generate the autocompletion script for powershell. To load completions in your current shell session: completion powershell | Out-String | Invoke-Expression To load completions for every new session, add the output of the above command to your powershell profile. completion powershell [flags]","title":"Synopsis"},{"location":"server/cmdref/_completion_powershell/#options","text":"-h, --help help for powershell --no-descriptions disable completion descriptions","title":"Options"},{"location":"server/cmdref/_completion_powershell/#see-also","text":"completion - Generate the autocompletion script for the specified shell","title":"SEE ALSO"},{"location":"server/cmdref/_completion_zsh/","text":"completion zsh \u00b6 Generate the autocompletion script for zsh Synopsis \u00b6 Generate the autocompletion script for the zsh shell. If shell completion is not already enabled in your environment you will need to enable it. You can execute the following once: echo \"autoload -U compinit; compinit\" >> ~/. zshrc To load completions in your current shell session: source <( completion zsh); compdef _ To load completions for every new session, execute once: Linux: \u00b6 completion zsh > \" ${ fpath [ 1 ] } /_\" macOS: \u00b6 completion zsh > $(brew --prefix)/share/zsh/site-functions/_ You will need to start a new shell for this setup to take effect. completion zsh [flags] Options \u00b6 -h, --help help for zsh --no-descriptions disable completion descriptions SEE ALSO \u00b6 completion - Generate the autocompletion script for the specified shell","title":" completion zsh"},{"location":"server/cmdref/_completion_zsh/#completion-zsh","text":"Generate the autocompletion script for zsh","title":"completion zsh"},{"location":"server/cmdref/_completion_zsh/#synopsis","text":"Generate the autocompletion script for the zsh shell. If shell completion is not already enabled in your environment you will need to enable it. You can execute the following once: echo \"autoload -U compinit; compinit\" >> ~/. zshrc To load completions in your current shell session: source <( completion zsh); compdef _ To load completions for every new session, execute once:","title":"Synopsis"},{"location":"server/cmdref/_completion_zsh/#linux","text":"completion zsh > \" ${ fpath [ 1 ] } /_\"","title":"Linux:"},{"location":"server/cmdref/_completion_zsh/#macos","text":"completion zsh > $(brew --prefix)/share/zsh/site-functions/_ You will need to start a new shell for this setup to take effect. completion zsh [flags]","title":"macOS:"},{"location":"server/cmdref/_completion_zsh/#options","text":"-h, --help help for zsh --no-descriptions disable completion descriptions","title":"Options"},{"location":"server/cmdref/_completion_zsh/#see-also","text":"completion - Generate the autocompletion script for the specified shell","title":"SEE ALSO"},{"location":"server/cmdref/kjournal-apiserver/","text":"kjournal-apiserver \u00b6 Launches the kjournal kubernetes apiserver Synopsis \u00b6 Launch a wardle API server kjournal-apiserver [flags] Options \u00b6 --admission-control-config-file string File with admission control configuration. --audit-log-batch-buffer-size int The size of the buffer to store events before batching and writing. Only used in batch mode. (default 10000) --audit-log-batch-max-size int The maximum size of a batch. Only used in batch mode. (default 1) --audit-log-batch-max-wait duration The amount of time to wait before force writing the batch that hadn't reached the max size. Only used in batch mode. --audit-log-batch-throttle-burst int Maximum number of requests sent at the same moment if ThrottleQPS was not utilized before. Only used in batch mode. --audit-log-batch-throttle-enable Whether batching throttling is enabled. Only used in batch mode. --audit-log-batch-throttle-qps float32 Maximum average number of batches per second. Only used in batch mode. --audit-log-compress If set, the rotated log files will be compressed using gzip. --audit-log-format string Format of saved audits. \"legacy\" indicates 1-line text format for each event. \"json\" indicates structured json format. Known formats are legacy,json. (default \"json\") --audit-log-maxage int The maximum number of days to retain old audit log files based on the timestamp encoded in their filename. --audit-log-maxbackup int The maximum number of old audit log files to retain. Setting a value of 0 will mean there's no restriction on the number of files. --audit-log-maxsize int The maximum size in megabytes of the audit log file before it gets rotated. --audit-log-mode string Strategy for sending audit events. Blocking indicates sending events should block server responses. Batch causes the backend to buffer and write events asynchronously. Known modes are batch,blocking,blocking-strict. (default \"blocking\") --audit-log-path string If set, all requests coming to the apiserver will be logged to this file. '-' means standard out. --audit-log-truncate-enabled Whether event and batch truncating is enabled. --audit-log-truncate-max-batch-size int Maximum size of the batch sent to the underlying backend. Actual serialized size can be several hundreds of bytes greater. If a batch exceeds this limit, it is split into several batches of smaller size. (default 10485760) --audit-log-truncate-max-event-size int Maximum size of the audit event sent to the underlying backend. If the size of an event is greater than this number, first request and response are removed, and if this doesn't reduce the size enough, event is discarded. (default 102400) --audit-log-version string API group and version used for serializing audit events written to log. (default \"audit.k8s.io/v1\") --audit-policy-file string Path to the file that defines the audit policy configuration. --audit-webhook-batch-buffer-size int The size of the buffer to store events before batching and writing. Only used in batch mode. (default 10000) --audit-webhook-batch-max-size int The maximum size of a batch. Only used in batch mode. (default 400) --audit-webhook-batch-max-wait duration The amount of time to wait before force writing the batch that hadn't reached the max size. Only used in batch mode. (default 30s) --audit-webhook-batch-throttle-burst int Maximum number of requests sent at the same moment if ThrottleQPS was not utilized before. Only used in batch mode. (default 15) --audit-webhook-batch-throttle-enable Whether batching throttling is enabled. Only used in batch mode. (default true) --audit-webhook-batch-throttle-qps float32 Maximum average number of batches per second. Only used in batch mode. (default 10) --audit-webhook-config-file string Path to a kubeconfig formatted file that defines the audit webhook configuration. --audit-webhook-initial-backoff duration The amount of time to wait before retrying the first failed request. (default 10s) --audit-webhook-mode string Strategy for sending audit events. Blocking indicates sending events should block server responses. Batch causes the backend to buffer and write events asynchronously. Known modes are batch,blocking,blocking-strict. (default \"batch\") --audit-webhook-truncate-enabled Whether event and batch truncating is enabled. --audit-webhook-truncate-max-batch-size int Maximum size of the batch sent to the underlying backend. Actual serialized size can be several hundreds of bytes greater. If a batch exceeds this limit, it is split into several batches of smaller size. (default 10485760) --audit-webhook-truncate-max-event-size int Maximum size of the audit event sent to the underlying backend. If the size of an event is greater than this number, first request and response are removed, and if this doesn't reduce the size enough, event is discarded. (default 102400) --audit-webhook-version string API group and version used for serializing audit events written to webhook. (default \"audit.k8s.io/v1\") --authentication-kubeconfig string kubeconfig file pointing at the 'core' kubernetes server with enough rights to create tokenreviews.authentication.k8s.io. --authentication-skip-lookup If false, the authentication-kubeconfig will be used to lookup missing authentication configuration from the cluster. --authentication-token-webhook-cache-ttl duration The duration to cache responses from the webhook token authenticator. (default 10s) --authentication-tolerate-lookup-failure If true, failures to look up missing authentication configuration from the cluster are not considered fatal. Note that this can result in authentication that treats all requests as anonymous. --authorization-always-allow-paths strings A list of HTTP paths to skip during authorization, i.e. these are authorized without contacting the 'core' kubernetes server. (default [/healthz,/readyz,/livez]) --authorization-kubeconfig string kubeconfig file pointing at the 'core' kubernetes server with enough rights to create subjectaccessreviews.authorization.k8s.io. --authorization-webhook-cache-authorized-ttl duration The duration to cache 'authorized' responses from the webhook authorizer. (default 10s) --authorization-webhook-cache-unauthorized-ttl duration The duration to cache 'unauthorized' responses from the webhook authorizer. (default 10s) --bind-address ip The IP address on which to listen for the --secure-port port. The associated interface(s) must be reachable by the rest of the cluster, and by CLI/web clients. If blank or an unspecified address (0.0.0.0 or ::), all interfaces will be used. (default 0.0.0.0) --cert-dir string The directory where the TLS certs are located. If --tls-cert-file and --tls-private-key-file are provided, this flag will be ignored. (default \"apiserver.local.config/certificates\") --client-ca-file string If set, any request presenting a client certificate signed by one of the authorities in the client-ca-file is authenticated with an identity corresponding to the CommonName of the client certificate. --config string Path to kjournal config --contention-profiling Enable lock contention profiling, if profiling is enabled --delete-collection-workers int Number of workers spawned for DeleteCollection call. These are used to speed up namespace cleanup. (default 1) --disable-admission-plugins strings admission plugins that should be disabled although they are in the default enabled plugins list (NamespaceLifecycle, MutatingAdmissionWebhook, ValidatingAdmissionWebhook). Comma-delimited list of admission plugins: MutatingAdmissionWebhook, NamespaceLifecycle, ValidatingAdmissionWebhook. The order of plugins in this flag does not matter. --egress-selector-config-file string File with apiserver egress selector configuration. --enable-admission-plugins strings admission plugins that should be enabled in addition to default enabled ones (NamespaceLifecycle, MutatingAdmissionWebhook, ValidatingAdmissionWebhook). Comma-delimited list of admission plugins: MutatingAdmissionWebhook, NamespaceLifecycle, ValidatingAdmissionWebhook. The order of plugins in this flag does not matter. --enable-garbage-collector Enables the generic garbage collector. MUST be synced with the corresponding flag of the kube-controller-manager. (default true) --encryption-provider-config string The file containing configuration for encryption providers to be used for storing secrets in etcd --etcd-readycheck-timeout duration The timeout to use when checking etcd readiness (default 2s) --feature-gates mapStringBool A set of key=value pairs that describe feature gates for alpha/experimental features. Options are: APIListChunking=true|false (BETA - default=true) APIPriorityAndFairness=true|false (BETA - default=true) APIResponseCompression=true|false (BETA - default=true) APIServerIdentity=true|false (ALPHA - default=false) APIServerTracing=true|false (ALPHA - default=false) AllAlpha=true|false (ALPHA - default=false) AllBeta=true|false (BETA - default=false) CustomResourceValidationExpressions=true|false (BETA - default=true) KMSv2=true|false (ALPHA - default=false) OpenAPIEnums=true|false (BETA - default=true) OpenAPIV3=true|false (BETA - default=true) RemainingItemCount=true|false (BETA - default=true) ServerSideFieldValidation=true|false (BETA - default=true) StorageVersionAPI=true|false (ALPHA - default=false) StorageVersionHash=true|false (BETA - default=true) -h, --help help for kjournal-apiserver --http2-max-streams-per-connection int The limit that the server gives to clients for the maximum number of streams in an HTTP/2 connection. Zero means to use golang's default. (default 1000) --kubeconfig string kubeconfig file pointing at the 'core' kubernetes server. --lease-reuse-duration-seconds int The time in seconds that each lease is reused. A lower value could avoid large number of objects reusing the same lease. Notice that a too small value may cause performance problems at storage layer. (default 60) --permit-address-sharing If true, SO_REUSEADDR will be used when binding the port. This allows binding to wildcard IPs like 0.0.0.0 and specific IPs in parallel, and it avoids waiting for the kernel to release sockets in TIME_WAIT state. [default=false] --permit-port-sharing If true, SO_REUSEPORT will be used when binding the port, which allows more than one instance to bind on the same address and port. [default=false] --profiling Enable profiling via web interface host:port/debug/pprof/ (default true) --requestheader-allowed-names strings List of client certificate common names to allow to provide usernames in headers specified by --requestheader-username-headers. If empty, any client certificate validated by the authorities in --requestheader-client-ca-file is allowed. --requestheader-client-ca-file string Root certificate bundle to use to verify client certificates on incoming requests before trusting usernames in headers specified by --requestheader-username-headers. WARNING: generally do not depend on authorization being already done for incoming requests. --requestheader-extra-headers-prefix strings List of request header prefixes to inspect. X-Remote-Extra- is suggested. (default [x-remote-extra-]) --requestheader-group-headers strings List of request headers to inspect for groups. X-Remote-Group is suggested. (default [x-remote-group]) --requestheader-username-headers strings List of request headers to inspect for usernames. X-Remote-User is common. (default [x-remote-user]) --secure-port int The port on which to serve HTTPS with authentication and authorization. If 0, don't serve HTTPS at all. (default 443) --standalone-debug-mode Under the local-debug mode the apiserver will allow all access to its resources without authorizing the requests, this flag is only intended for debugging in your workstation and the apiserver will be crashing if its binding address is not 127.0.0.1. --storage-backend string The storage backend for persistence. Options: 'etcd3' (default). --storage-media-type string The media type to use to store objects in storage. Some resources or storage backends may only support a specific media type and will ignore this setting. (default \"application/json\") --tls-cert-file string File containing the default x509 Certificate for HTTPS. (CA cert, if any, concatenated after server cert). If HTTPS serving is enabled, and --tls-cert-file and --tls-private-key-file are not provided, a self-signed certificate and key are generated for the public address and saved to the directory specified by --cert-dir. --tls-cipher-suites strings Comma-separated list of cipher suites for the server. If omitted, the default Go cipher suites will be used. Preferred values: TLS_AES_128_GCM_SHA256, TLS_AES_256_GCM_SHA384, TLS_CHACHA20_POLY1305_SHA256, TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA, TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305, TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305, TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256, TLS_RSA_WITH_AES_128_CBC_SHA, TLS_RSA_WITH_AES_128_GCM_SHA256, TLS_RSA_WITH_AES_256_CBC_SHA, TLS_RSA_WITH_AES_256_GCM_SHA384. Insecure values: TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256, TLS_ECDHE_ECDSA_WITH_RC4_128_SHA, TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256, TLS_ECDHE_RSA_WITH_RC4_128_SHA, TLS_RSA_WITH_3DES_EDE_CBC_SHA, TLS_RSA_WITH_AES_128_CBC_SHA256, TLS_RSA_WITH_RC4_128_SHA. --tls-min-version string Minimum TLS version supported. Possible values: VersionTLS10, VersionTLS11, VersionTLS12, VersionTLS13 --tls-private-key-file string File containing the default x509 private key matching --tls-cert-file. --tls-sni-cert-key namedCertKey A pair of x509 certificate and private key file paths, optionally suffixed with a list of domain patterns which are fully qualified domain names, possibly with prefixed wildcard segments. The domain patterns also allow IP addresses, but IPs should only be used if the apiserver has visibility to the IP address requested by a client. If no domain patterns are provided, the names of the certificate are extracted. Non-wildcard matches trump over wildcard matches, explicit domain patterns trump over extracted names. For multiple key/certificate pairs, use the --tls-sni-cert-key multiple times. Examples: \"example.crt,example.key\" or \"foo.crt,foo.key:*.foo.com,foo.com\". (default []) --tracing-config-file string File with apiserver tracing configuration. --watch-cache Enable watch caching in the apiserver (default true) --watch-cache-sizes strings Watch cache size settings for some resources (pods, nodes, etc.), comma separated. The individual setting format: resource[.group]#size, where resource is lowercase plural (no version), group is omitted for resources of apiVersion v1 (the legacy core API) and included for others, and size is a number. This option is only meaningful for resources built into the apiserver, not ones defined by CRDs or aggregated from external servers, and is only consulted if the watch-cache is enabled. The only meaningful size setting to supply here is zero, which means to disable watch caching for the associated resource; all non-zero values are equivalent and mean to not disable watch caching for that resource SEE ALSO \u00b6 kjournal-apiserver completion - Generate the autocompletion script for the specified shell","title":"Kjournal apiserver"},{"location":"server/cmdref/kjournal-apiserver/#kjournal-apiserver","text":"Launches the kjournal kubernetes apiserver","title":"kjournal-apiserver"},{"location":"server/cmdref/kjournal-apiserver/#synopsis","text":"Launch a wardle API server kjournal-apiserver [flags]","title":"Synopsis"},{"location":"server/cmdref/kjournal-apiserver/#options","text":"--admission-control-config-file string File with admission control configuration. --audit-log-batch-buffer-size int The size of the buffer to store events before batching and writing. Only used in batch mode. (default 10000) --audit-log-batch-max-size int The maximum size of a batch. Only used in batch mode. (default 1) --audit-log-batch-max-wait duration The amount of time to wait before force writing the batch that hadn't reached the max size. Only used in batch mode. --audit-log-batch-throttle-burst int Maximum number of requests sent at the same moment if ThrottleQPS was not utilized before. Only used in batch mode. --audit-log-batch-throttle-enable Whether batching throttling is enabled. Only used in batch mode. --audit-log-batch-throttle-qps float32 Maximum average number of batches per second. Only used in batch mode. --audit-log-compress If set, the rotated log files will be compressed using gzip. --audit-log-format string Format of saved audits. \"legacy\" indicates 1-line text format for each event. \"json\" indicates structured json format. Known formats are legacy,json. (default \"json\") --audit-log-maxage int The maximum number of days to retain old audit log files based on the timestamp encoded in their filename. --audit-log-maxbackup int The maximum number of old audit log files to retain. Setting a value of 0 will mean there's no restriction on the number of files. --audit-log-maxsize int The maximum size in megabytes of the audit log file before it gets rotated. --audit-log-mode string Strategy for sending audit events. Blocking indicates sending events should block server responses. Batch causes the backend to buffer and write events asynchronously. Known modes are batch,blocking,blocking-strict. (default \"blocking\") --audit-log-path string If set, all requests coming to the apiserver will be logged to this file. '-' means standard out. --audit-log-truncate-enabled Whether event and batch truncating is enabled. --audit-log-truncate-max-batch-size int Maximum size of the batch sent to the underlying backend. Actual serialized size can be several hundreds of bytes greater. If a batch exceeds this limit, it is split into several batches of smaller size. (default 10485760) --audit-log-truncate-max-event-size int Maximum size of the audit event sent to the underlying backend. If the size of an event is greater than this number, first request and response are removed, and if this doesn't reduce the size enough, event is discarded. (default 102400) --audit-log-version string API group and version used for serializing audit events written to log. (default \"audit.k8s.io/v1\") --audit-policy-file string Path to the file that defines the audit policy configuration. --audit-webhook-batch-buffer-size int The size of the buffer to store events before batching and writing. Only used in batch mode. (default 10000) --audit-webhook-batch-max-size int The maximum size of a batch. Only used in batch mode. (default 400) --audit-webhook-batch-max-wait duration The amount of time to wait before force writing the batch that hadn't reached the max size. Only used in batch mode. (default 30s) --audit-webhook-batch-throttle-burst int Maximum number of requests sent at the same moment if ThrottleQPS was not utilized before. Only used in batch mode. (default 15) --audit-webhook-batch-throttle-enable Whether batching throttling is enabled. Only used in batch mode. (default true) --audit-webhook-batch-throttle-qps float32 Maximum average number of batches per second. Only used in batch mode. (default 10) --audit-webhook-config-file string Path to a kubeconfig formatted file that defines the audit webhook configuration. --audit-webhook-initial-backoff duration The amount of time to wait before retrying the first failed request. (default 10s) --audit-webhook-mode string Strategy for sending audit events. Blocking indicates sending events should block server responses. Batch causes the backend to buffer and write events asynchronously. Known modes are batch,blocking,blocking-strict. (default \"batch\") --audit-webhook-truncate-enabled Whether event and batch truncating is enabled. --audit-webhook-truncate-max-batch-size int Maximum size of the batch sent to the underlying backend. Actual serialized size can be several hundreds of bytes greater. If a batch exceeds this limit, it is split into several batches of smaller size. (default 10485760) --audit-webhook-truncate-max-event-size int Maximum size of the audit event sent to the underlying backend. If the size of an event is greater than this number, first request and response are removed, and if this doesn't reduce the size enough, event is discarded. (default 102400) --audit-webhook-version string API group and version used for serializing audit events written to webhook. (default \"audit.k8s.io/v1\") --authentication-kubeconfig string kubeconfig file pointing at the 'core' kubernetes server with enough rights to create tokenreviews.authentication.k8s.io. --authentication-skip-lookup If false, the authentication-kubeconfig will be used to lookup missing authentication configuration from the cluster. --authentication-token-webhook-cache-ttl duration The duration to cache responses from the webhook token authenticator. (default 10s) --authentication-tolerate-lookup-failure If true, failures to look up missing authentication configuration from the cluster are not considered fatal. Note that this can result in authentication that treats all requests as anonymous. --authorization-always-allow-paths strings A list of HTTP paths to skip during authorization, i.e. these are authorized without contacting the 'core' kubernetes server. (default [/healthz,/readyz,/livez]) --authorization-kubeconfig string kubeconfig file pointing at the 'core' kubernetes server with enough rights to create subjectaccessreviews.authorization.k8s.io. --authorization-webhook-cache-authorized-ttl duration The duration to cache 'authorized' responses from the webhook authorizer. (default 10s) --authorization-webhook-cache-unauthorized-ttl duration The duration to cache 'unauthorized' responses from the webhook authorizer. (default 10s) --bind-address ip The IP address on which to listen for the --secure-port port. The associated interface(s) must be reachable by the rest of the cluster, and by CLI/web clients. If blank or an unspecified address (0.0.0.0 or ::), all interfaces will be used. (default 0.0.0.0) --cert-dir string The directory where the TLS certs are located. If --tls-cert-file and --tls-private-key-file are provided, this flag will be ignored. (default \"apiserver.local.config/certificates\") --client-ca-file string If set, any request presenting a client certificate signed by one of the authorities in the client-ca-file is authenticated with an identity corresponding to the CommonName of the client certificate. --config string Path to kjournal config --contention-profiling Enable lock contention profiling, if profiling is enabled --delete-collection-workers int Number of workers spawned for DeleteCollection call. These are used to speed up namespace cleanup. (default 1) --disable-admission-plugins strings admission plugins that should be disabled although they are in the default enabled plugins list (NamespaceLifecycle, MutatingAdmissionWebhook, ValidatingAdmissionWebhook). Comma-delimited list of admission plugins: MutatingAdmissionWebhook, NamespaceLifecycle, ValidatingAdmissionWebhook. The order of plugins in this flag does not matter. --egress-selector-config-file string File with apiserver egress selector configuration. --enable-admission-plugins strings admission plugins that should be enabled in addition to default enabled ones (NamespaceLifecycle, MutatingAdmissionWebhook, ValidatingAdmissionWebhook). Comma-delimited list of admission plugins: MutatingAdmissionWebhook, NamespaceLifecycle, ValidatingAdmissionWebhook. The order of plugins in this flag does not matter. --enable-garbage-collector Enables the generic garbage collector. MUST be synced with the corresponding flag of the kube-controller-manager. (default true) --encryption-provider-config string The file containing configuration for encryption providers to be used for storing secrets in etcd --etcd-readycheck-timeout duration The timeout to use when checking etcd readiness (default 2s) --feature-gates mapStringBool A set of key=value pairs that describe feature gates for alpha/experimental features. Options are: APIListChunking=true|false (BETA - default=true) APIPriorityAndFairness=true|false (BETA - default=true) APIResponseCompression=true|false (BETA - default=true) APIServerIdentity=true|false (ALPHA - default=false) APIServerTracing=true|false (ALPHA - default=false) AllAlpha=true|false (ALPHA - default=false) AllBeta=true|false (BETA - default=false) CustomResourceValidationExpressions=true|false (BETA - default=true) KMSv2=true|false (ALPHA - default=false) OpenAPIEnums=true|false (BETA - default=true) OpenAPIV3=true|false (BETA - default=true) RemainingItemCount=true|false (BETA - default=true) ServerSideFieldValidation=true|false (BETA - default=true) StorageVersionAPI=true|false (ALPHA - default=false) StorageVersionHash=true|false (BETA - default=true) -h, --help help for kjournal-apiserver --http2-max-streams-per-connection int The limit that the server gives to clients for the maximum number of streams in an HTTP/2 connection. Zero means to use golang's default. (default 1000) --kubeconfig string kubeconfig file pointing at the 'core' kubernetes server. --lease-reuse-duration-seconds int The time in seconds that each lease is reused. A lower value could avoid large number of objects reusing the same lease. Notice that a too small value may cause performance problems at storage layer. (default 60) --permit-address-sharing If true, SO_REUSEADDR will be used when binding the port. This allows binding to wildcard IPs like 0.0.0.0 and specific IPs in parallel, and it avoids waiting for the kernel to release sockets in TIME_WAIT state. [default=false] --permit-port-sharing If true, SO_REUSEPORT will be used when binding the port, which allows more than one instance to bind on the same address and port. [default=false] --profiling Enable profiling via web interface host:port/debug/pprof/ (default true) --requestheader-allowed-names strings List of client certificate common names to allow to provide usernames in headers specified by --requestheader-username-headers. If empty, any client certificate validated by the authorities in --requestheader-client-ca-file is allowed. --requestheader-client-ca-file string Root certificate bundle to use to verify client certificates on incoming requests before trusting usernames in headers specified by --requestheader-username-headers. WARNING: generally do not depend on authorization being already done for incoming requests. --requestheader-extra-headers-prefix strings List of request header prefixes to inspect. X-Remote-Extra- is suggested. (default [x-remote-extra-]) --requestheader-group-headers strings List of request headers to inspect for groups. X-Remote-Group is suggested. (default [x-remote-group]) --requestheader-username-headers strings List of request headers to inspect for usernames. X-Remote-User is common. (default [x-remote-user]) --secure-port int The port on which to serve HTTPS with authentication and authorization. If 0, don't serve HTTPS at all. (default 443) --standalone-debug-mode Under the local-debug mode the apiserver will allow all access to its resources without authorizing the requests, this flag is only intended for debugging in your workstation and the apiserver will be crashing if its binding address is not 127.0.0.1. --storage-backend string The storage backend for persistence. Options: 'etcd3' (default). --storage-media-type string The media type to use to store objects in storage. Some resources or storage backends may only support a specific media type and will ignore this setting. (default \"application/json\") --tls-cert-file string File containing the default x509 Certificate for HTTPS. (CA cert, if any, concatenated after server cert). If HTTPS serving is enabled, and --tls-cert-file and --tls-private-key-file are not provided, a self-signed certificate and key are generated for the public address and saved to the directory specified by --cert-dir. --tls-cipher-suites strings Comma-separated list of cipher suites for the server. If omitted, the default Go cipher suites will be used. Preferred values: TLS_AES_128_GCM_SHA256, TLS_AES_256_GCM_SHA384, TLS_CHACHA20_POLY1305_SHA256, TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA, TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305, TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305, TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256, TLS_RSA_WITH_AES_128_CBC_SHA, TLS_RSA_WITH_AES_128_GCM_SHA256, TLS_RSA_WITH_AES_256_CBC_SHA, TLS_RSA_WITH_AES_256_GCM_SHA384. Insecure values: TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256, TLS_ECDHE_ECDSA_WITH_RC4_128_SHA, TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256, TLS_ECDHE_RSA_WITH_RC4_128_SHA, TLS_RSA_WITH_3DES_EDE_CBC_SHA, TLS_RSA_WITH_AES_128_CBC_SHA256, TLS_RSA_WITH_RC4_128_SHA. --tls-min-version string Minimum TLS version supported. Possible values: VersionTLS10, VersionTLS11, VersionTLS12, VersionTLS13 --tls-private-key-file string File containing the default x509 private key matching --tls-cert-file. --tls-sni-cert-key namedCertKey A pair of x509 certificate and private key file paths, optionally suffixed with a list of domain patterns which are fully qualified domain names, possibly with prefixed wildcard segments. The domain patterns also allow IP addresses, but IPs should only be used if the apiserver has visibility to the IP address requested by a client. If no domain patterns are provided, the names of the certificate are extracted. Non-wildcard matches trump over wildcard matches, explicit domain patterns trump over extracted names. For multiple key/certificate pairs, use the --tls-sni-cert-key multiple times. Examples: \"example.crt,example.key\" or \"foo.crt,foo.key:*.foo.com,foo.com\". (default []) --tracing-config-file string File with apiserver tracing configuration. --watch-cache Enable watch caching in the apiserver (default true) --watch-cache-sizes strings Watch cache size settings for some resources (pods, nodes, etc.), comma separated. The individual setting format: resource[.group]#size, where resource is lowercase plural (no version), group is omitted for resources of apiVersion v1 (the legacy core API) and included for others, and size is a number. This option is only meaningful for resources built into the apiserver, not ones defined by CRDs or aggregated from external servers, and is only consulted if the watch-cache is enabled. The only meaningful size setting to supply here is zero, which means to disable watch caching for the associated resource; all non-zero values are equivalent and mean to not disable watch caching for that resource","title":"Options"},{"location":"server/cmdref/kjournal-apiserver/#see-also","text":"kjournal-apiserver completion - Generate the autocompletion script for the specified shell","title":"SEE ALSO"},{"location":"server/cmdref/kjournal-apiserver_completion/","text":"kjournal-apiserver completion \u00b6 Generate the autocompletion script for the specified shell Synopsis \u00b6 Generate the autocompletion script for kjournal-apiserver for the specified shell. See each sub-command's help for details on how to use the generated script. Options \u00b6 -h, --help help for completion SEE ALSO \u00b6 kjournal-apiserver - Launches the kjournal kubernetes apiserver kjournal-apiserver completion bash - Generate the autocompletion script for bash kjournal-apiserver completion fish - Generate the autocompletion script for fish kjournal-apiserver completion powershell - Generate the autocompletion script for powershell kjournal-apiserver completion zsh - Generate the autocompletion script for zsh","title":"Kjournal apiserver completion"},{"location":"server/cmdref/kjournal-apiserver_completion/#kjournal-apiserver-completion","text":"Generate the autocompletion script for the specified shell","title":"kjournal-apiserver completion"},{"location":"server/cmdref/kjournal-apiserver_completion/#synopsis","text":"Generate the autocompletion script for kjournal-apiserver for the specified shell. See each sub-command's help for details on how to use the generated script.","title":"Synopsis"},{"location":"server/cmdref/kjournal-apiserver_completion/#options","text":"-h, --help help for completion","title":"Options"},{"location":"server/cmdref/kjournal-apiserver_completion/#see-also","text":"kjournal-apiserver - Launches the kjournal kubernetes apiserver kjournal-apiserver completion bash - Generate the autocompletion script for bash kjournal-apiserver completion fish - Generate the autocompletion script for fish kjournal-apiserver completion powershell - Generate the autocompletion script for powershell kjournal-apiserver completion zsh - Generate the autocompletion script for zsh","title":"SEE ALSO"},{"location":"server/cmdref/kjournal-apiserver_completion_bash/","text":"kjournal-apiserver completion bash \u00b6 Generate the autocompletion script for bash Synopsis \u00b6 Generate the autocompletion script for the bash shell. This script depends on the 'bash-completion' package. If it is not installed already, you can install it via your OS's package manager. To load completions in your current shell session: source <(kjournal-apiserver completion bash) To load completions for every new session, execute once: Linux: \u00b6 kjournal-apiserver completion bash > /etc/bash_completion.d/kjournal-apiserver macOS: \u00b6 kjournal-apiserver completion bash > $(brew --prefix)/etc/bash_completion.d/kjournal-apiserver You will need to start a new shell for this setup to take effect. kjournal-apiserver completion bash Options \u00b6 -h, --help help for bash --no-descriptions disable completion descriptions SEE ALSO \u00b6 kjournal-apiserver completion - Generate the autocompletion script for the specified shell","title":"Kjournal apiserver completion bash"},{"location":"server/cmdref/kjournal-apiserver_completion_bash/#kjournal-apiserver-completion-bash","text":"Generate the autocompletion script for bash","title":"kjournal-apiserver completion bash"},{"location":"server/cmdref/kjournal-apiserver_completion_bash/#synopsis","text":"Generate the autocompletion script for the bash shell. This script depends on the 'bash-completion' package. If it is not installed already, you can install it via your OS's package manager. To load completions in your current shell session: source <(kjournal-apiserver completion bash) To load completions for every new session, execute once:","title":"Synopsis"},{"location":"server/cmdref/kjournal-apiserver_completion_bash/#linux","text":"kjournal-apiserver completion bash > /etc/bash_completion.d/kjournal-apiserver","title":"Linux:"},{"location":"server/cmdref/kjournal-apiserver_completion_bash/#macos","text":"kjournal-apiserver completion bash > $(brew --prefix)/etc/bash_completion.d/kjournal-apiserver You will need to start a new shell for this setup to take effect. kjournal-apiserver completion bash","title":"macOS:"},{"location":"server/cmdref/kjournal-apiserver_completion_bash/#options","text":"-h, --help help for bash --no-descriptions disable completion descriptions","title":"Options"},{"location":"server/cmdref/kjournal-apiserver_completion_bash/#see-also","text":"kjournal-apiserver completion - Generate the autocompletion script for the specified shell","title":"SEE ALSO"},{"location":"server/cmdref/kjournal-apiserver_completion_fish/","text":"kjournal-apiserver completion fish \u00b6 Generate the autocompletion script for fish Synopsis \u00b6 Generate the autocompletion script for the fish shell. To load completions in your current shell session: kjournal-apiserver completion fish | source To load completions for every new session, execute once: kjournal-apiserver completion fish > ~/.config/fish/completions/kjournal-apiserver.fish You will need to start a new shell for this setup to take effect. kjournal-apiserver completion fish [flags] Options \u00b6 -h, --help help for fish --no-descriptions disable completion descriptions SEE ALSO \u00b6 kjournal-apiserver completion - Generate the autocompletion script for the specified shell","title":"Kjournal apiserver completion fish"},{"location":"server/cmdref/kjournal-apiserver_completion_fish/#kjournal-apiserver-completion-fish","text":"Generate the autocompletion script for fish","title":"kjournal-apiserver completion fish"},{"location":"server/cmdref/kjournal-apiserver_completion_fish/#synopsis","text":"Generate the autocompletion script for the fish shell. To load completions in your current shell session: kjournal-apiserver completion fish | source To load completions for every new session, execute once: kjournal-apiserver completion fish > ~/.config/fish/completions/kjournal-apiserver.fish You will need to start a new shell for this setup to take effect. kjournal-apiserver completion fish [flags]","title":"Synopsis"},{"location":"server/cmdref/kjournal-apiserver_completion_fish/#options","text":"-h, --help help for fish --no-descriptions disable completion descriptions","title":"Options"},{"location":"server/cmdref/kjournal-apiserver_completion_fish/#see-also","text":"kjournal-apiserver completion - Generate the autocompletion script for the specified shell","title":"SEE ALSO"},{"location":"server/cmdref/kjournal-apiserver_completion_powershell/","text":"kjournal-apiserver completion powershell \u00b6 Generate the autocompletion script for powershell Synopsis \u00b6 Generate the autocompletion script for powershell. To load completions in your current shell session: kjournal-apiserver completion powershell | Out-String | Invoke-Expression To load completions for every new session, add the output of the above command to your powershell profile. kjournal-apiserver completion powershell [flags] Options \u00b6 -h, --help help for powershell --no-descriptions disable completion descriptions SEE ALSO \u00b6 kjournal-apiserver completion - Generate the autocompletion script for the specified shell","title":"Kjournal apiserver completion powershell"},{"location":"server/cmdref/kjournal-apiserver_completion_powershell/#kjournal-apiserver-completion-powershell","text":"Generate the autocompletion script for powershell","title":"kjournal-apiserver completion powershell"},{"location":"server/cmdref/kjournal-apiserver_completion_powershell/#synopsis","text":"Generate the autocompletion script for powershell. To load completions in your current shell session: kjournal-apiserver completion powershell | Out-String | Invoke-Expression To load completions for every new session, add the output of the above command to your powershell profile. kjournal-apiserver completion powershell [flags]","title":"Synopsis"},{"location":"server/cmdref/kjournal-apiserver_completion_powershell/#options","text":"-h, --help help for powershell --no-descriptions disable completion descriptions","title":"Options"},{"location":"server/cmdref/kjournal-apiserver_completion_powershell/#see-also","text":"kjournal-apiserver completion - Generate the autocompletion script for the specified shell","title":"SEE ALSO"},{"location":"server/cmdref/kjournal-apiserver_completion_zsh/","text":"kjournal-apiserver completion zsh \u00b6 Generate the autocompletion script for zsh Synopsis \u00b6 Generate the autocompletion script for the zsh shell. If shell completion is not already enabled in your environment you will need to enable it. You can execute the following once: echo \"autoload -U compinit; compinit\" >> ~/. zshrc To load completions in your current shell session: source <(kjournal-apiserver completion zsh); compdef _kjournal-apiserver kjournal-apiserver To load completions for every new session, execute once: Linux: \u00b6 kjournal-apiserver completion zsh > \" ${ fpath [ 1 ] } /_kjournal-apiserver\" macOS: \u00b6 kjournal-apiserver completion zsh > $(brew --prefix)/share/zsh/site-functions/_kjournal-apiserver You will need to start a new shell for this setup to take effect. kjournal-apiserver completion zsh [flags] Options \u00b6 -h, --help help for zsh --no-descriptions disable completion descriptions SEE ALSO \u00b6 kjournal-apiserver completion - Generate the autocompletion script for the specified shell","title":"Kjournal apiserver completion zsh"},{"location":"server/cmdref/kjournal-apiserver_completion_zsh/#kjournal-apiserver-completion-zsh","text":"Generate the autocompletion script for zsh","title":"kjournal-apiserver completion zsh"},{"location":"server/cmdref/kjournal-apiserver_completion_zsh/#synopsis","text":"Generate the autocompletion script for the zsh shell. If shell completion is not already enabled in your environment you will need to enable it. You can execute the following once: echo \"autoload -U compinit; compinit\" >> ~/. zshrc To load completions in your current shell session: source <(kjournal-apiserver completion zsh); compdef _kjournal-apiserver kjournal-apiserver To load completions for every new session, execute once:","title":"Synopsis"},{"location":"server/cmdref/kjournal-apiserver_completion_zsh/#linux","text":"kjournal-apiserver completion zsh > \" ${ fpath [ 1 ] } /_kjournal-apiserver\"","title":"Linux:"},{"location":"server/cmdref/kjournal-apiserver_completion_zsh/#macos","text":"kjournal-apiserver completion zsh > $(brew --prefix)/share/zsh/site-functions/_kjournal-apiserver You will need to start a new shell for this setup to take effect. kjournal-apiserver completion zsh [flags]","title":"macOS:"},{"location":"server/cmdref/kjournal-apiserver_completion_zsh/#options","text":"-h, --help help for zsh --no-descriptions disable completion descriptions","title":"Options"},{"location":"server/cmdref/kjournal-apiserver_completion_zsh/#see-also","text":"kjournal-apiserver completion - Generate the autocompletion script for the specified shell","title":"SEE ALSO"},{"location":"server/methods/helm/","text":"kjournal \u00b6 A Helm chart for kjournal Homepage: https://github.com/raffis/kjournal Maintainers \u00b6 Name Email Url raffis raffael.sahli@gmail.com Source Code \u00b6 https://github.com/raffis/kjournal Values \u00b6 Key Type Default Description affinity object {} apiserverConfig.config string \"\" apiserverConfig.existingConfigMap string nil apiserverConfig.templateName string \"elasticsearch-kjournal-structured\" certManager.caCertDuration string \"43800h\" certManager.certDuration string \"8760h\" certManager.enabled bool false customAnnotations object {} customLabels object {} dnsConfig object {} env list [] extraArguments list [] extraVolumeMounts list [] extraVolumes list [] hostNetwork.enabled bool false image.pullPolicy string \"IfNotPresent\" image.repository string \"ghcr.io/raffis/kjournal/apiserver\" image.tag string nil listenPort int 8443 livenessProbe.httpGet.path string \"/healthz\" livenessProbe.httpGet.port string \"https\" livenessProbe.httpGet.scheme string \"HTTPS\" livenessProbe.initialDelaySeconds int 5 livenessProbe.timeoutSeconds int 5 namespaceOverride string \"\" nodeSelector object {} podAnnotations object {} podDisruptionBudget.enabled bool false podDisruptionBudget.maxUnavailable int 1 podDisruptionBudget.minAvailable string nil podLabels object {} podSecurityContext.fsGroup int 10001 priorityClassName string \"\" rbac.create bool true readinessProbe.httpGet.path string \"/healthz\" readinessProbe.httpGet.port string \"https\" readinessProbe.httpGet.scheme string \"HTTPS\" readinessProbe.initialDelaySeconds int 5 readinessProbe.timeoutSeconds int 5 replicas int 1 resources.limits.cpu string \"1\" resources.limits.memory string \"200Mi\" resources.requests.cpu string \"100m\" resources.requests.memory string \"20Mi\" securityContext.allowPrivilegeEscalation bool false securityContext.capabilities.drop[0] string \"ALL\" securityContext.readOnlyRootFilesystem bool true securityContext.runAsNonRoot bool true securityContext.seccompProfile.type string \"RuntimeDefault\" service.annotations object {} service.port int 443 service.type string \"ClusterIP\" serviceAccount.annotations object {} serviceAccount.create bool true serviceAccount.name string nil serviceMonitor.enabled bool false strategy.rollingUpdate.maxSurge string \"25%\" strategy.rollingUpdate.maxUnavailable string \"25%\" strategy.type string \"RollingUpdate\" tls.ca string \"# Public CA file that signed the APIService\" tls.certificate string \"# Public key of the APIService\" tls.enable bool false tls.key string \"# Private key of the APIService\" tolerations list [] topologySpreadConstraints list []","title":"kjournal"},{"location":"server/methods/helm/#kjournal","text":"A Helm chart for kjournal Homepage: https://github.com/raffis/kjournal","title":"kjournal"},{"location":"server/methods/helm/#maintainers","text":"Name Email Url raffis raffael.sahli@gmail.com","title":"Maintainers"},{"location":"server/methods/helm/#source-code","text":"https://github.com/raffis/kjournal","title":"Source Code"},{"location":"server/methods/helm/#values","text":"Key Type Default Description affinity object {} apiserverConfig.config string \"\" apiserverConfig.existingConfigMap string nil apiserverConfig.templateName string \"elasticsearch-kjournal-structured\" certManager.caCertDuration string \"43800h\" certManager.certDuration string \"8760h\" certManager.enabled bool false customAnnotations object {} customLabels object {} dnsConfig object {} env list [] extraArguments list [] extraVolumeMounts list [] extraVolumes list [] hostNetwork.enabled bool false image.pullPolicy string \"IfNotPresent\" image.repository string \"ghcr.io/raffis/kjournal/apiserver\" image.tag string nil listenPort int 8443 livenessProbe.httpGet.path string \"/healthz\" livenessProbe.httpGet.port string \"https\" livenessProbe.httpGet.scheme string \"HTTPS\" livenessProbe.initialDelaySeconds int 5 livenessProbe.timeoutSeconds int 5 namespaceOverride string \"\" nodeSelector object {} podAnnotations object {} podDisruptionBudget.enabled bool false podDisruptionBudget.maxUnavailable int 1 podDisruptionBudget.minAvailable string nil podLabels object {} podSecurityContext.fsGroup int 10001 priorityClassName string \"\" rbac.create bool true readinessProbe.httpGet.path string \"/healthz\" readinessProbe.httpGet.port string \"https\" readinessProbe.httpGet.scheme string \"HTTPS\" readinessProbe.initialDelaySeconds int 5 readinessProbe.timeoutSeconds int 5 replicas int 1 resources.limits.cpu string \"1\" resources.limits.memory string \"200Mi\" resources.requests.cpu string \"100m\" resources.requests.memory string \"20Mi\" securityContext.allowPrivilegeEscalation bool false securityContext.capabilities.drop[0] string \"ALL\" securityContext.readOnlyRootFilesystem bool true securityContext.runAsNonRoot bool true securityContext.seccompProfile.type string \"RuntimeDefault\" service.annotations object {} service.port int 443 service.type string \"ClusterIP\" serviceAccount.annotations object {} serviceAccount.create bool true serviceAccount.name string nil serviceMonitor.enabled bool false strategy.rollingUpdate.maxSurge string \"25%\" strategy.rollingUpdate.maxUnavailable string \"25%\" strategy.type string \"RollingUpdate\" tls.ca string \"# Public CA file that signed the APIService\" tls.certificate string \"# Public key of the APIService\" tls.enable bool false tls.key string \"# Private key of the APIService\" tolerations list [] topologySpreadConstraints list []","title":"Values"},{"location":"server/storage/elasticsearch/","text":"Elasticsearch \u00b6 kjournal was first designed with elasticsearch as long-term storage backend. At this time it is also the only storage backend. kjournal-apiserver config flags \u00b6 The following flags are used by the apiserver to configure the elasticsearch storage backend. You will likely need to configure these. Flag Default Description --es-allow-insecure-tls not-set Allow insecure TLS connections. Do not verify the certificate --es-audit-index audit-* `` The index pattern where the kubernetes audit documents are stored. (For example: audit-*). You may specify multiple ones comma separated --es-audit-timestamp-field @timestamp The index field which is used as timestamop field for the audit documents --es-cacert `` Path to the CA (PEM) used to verify the server tls certificate --es-container-index logstash-* The index pattern where the kubernetes container logs are stored. (For example: logstash-*). You may specify multiple ones comma separated --es-container-namespace-field kubernetes.namespace_name.keyword The field which holds the kubernetes namespace. This field must not be indexed using any analyzers! Usually a .keyword field is wanted here --es-container-timestamp-field @timestamp The index field which is used as timestamop field for the audit documents --es-refresh-rate 500ms The refresh rate to poll from elasticsearch while checking for new documents during watch requests --es-url http://localhost:9200 Elasticsearch URL, you may add multiple ones comma separated Compatibility matrix \u00b6 kjournal-apiserver elasticsearch >= v0.0 >= v7.10","title":"Elasticsearch"},{"location":"server/storage/elasticsearch/#elasticsearch","text":"kjournal was first designed with elasticsearch as long-term storage backend. At this time it is also the only storage backend.","title":"Elasticsearch"},{"location":"server/storage/elasticsearch/#kjournal-apiserver-config-flags","text":"The following flags are used by the apiserver to configure the elasticsearch storage backend. You will likely need to configure these. Flag Default Description --es-allow-insecure-tls not-set Allow insecure TLS connections. Do not verify the certificate --es-audit-index audit-* `` The index pattern where the kubernetes audit documents are stored. (For example: audit-*). You may specify multiple ones comma separated --es-audit-timestamp-field @timestamp The index field which is used as timestamop field for the audit documents --es-cacert `` Path to the CA (PEM) used to verify the server tls certificate --es-container-index logstash-* The index pattern where the kubernetes container logs are stored. (For example: logstash-*). You may specify multiple ones comma separated --es-container-namespace-field kubernetes.namespace_name.keyword The field which holds the kubernetes namespace. This field must not be indexed using any analyzers! Usually a .keyword field is wanted here --es-container-timestamp-field @timestamp The index field which is used as timestamop field for the audit documents --es-refresh-rate 500ms The refresh rate to poll from elasticsearch while checking for new documents during watch requests --es-url http://localhost:9200 Elasticsearch URL, you may add multiple ones comma separated","title":"kjournal-apiserver config flags"},{"location":"server/storage/elasticsearch/#compatibility-matrix","text":"kjournal-apiserver elasticsearch >= v0.0 >= v7.10","title":"Compatibility matrix"},{"location":"server/storage/gcloud/","text":"Enable Admin SDK API Create ServiceAccount Create ServiceAccount key and download credentials as JSON","title":"Gcloud"},{"location":"server/storage/other/","text":"Need another storage? \u00b6 Currently only elasticsearch is supported. Happy to review a contribution to integrate other storage types. See [contributing guidelines]. The storage backend needs some form of field indexing to support filtering by at least resource name/types.","title":"Need another storage?"},{"location":"server/storage/other/#need-another-storage","text":"Currently only elasticsearch is supported. Happy to review a contribution to integrate other storage types. See [contributing guidelines]. The storage backend needs some form of field indexing to support filtering by at least resource name/types.","title":"Need another storage?"},{"location":"tutorials/kind/","text":"Try it using kind \u00b6 This tutorials rolls out a local kind cluster on your computer in order to test kjournal. We will deploy a single node kind control-plane, a single elasticsearch instance as well as fluent-bit for shipping. Requirements \u00b6 During this tutorial you need the following tools. Make sure you have them up-to-date. kubectl kustomize kind git kjournal Fetch the repo \u00b6 First lets clone the kjournal repository where we can access the deployment files for this tutorial. git clone https://github.com/raffis/kjournal cd kjournal Create kind cluster \u00b6 Let's create the kind cluster named kjournal first. Once the control plane is running we can continue. The apiserver is configured to log audit logs which is required if we want to query audit logs as well. kind create cluster --config config/kind-example/control-plane.yaml Deploy kjournal and third party components \u00b6 Next we deploy elasticsearch, fluent-bit, kubernetes-event-exporter as well as the kjournal apiserver itself from an opinated kustomize overlay. kustomize build config/kind-example --enable-helm | kubectl apply -f - Test kjournal \u00b6 Last but not least we can test if kjournal works properly. This command will start a watch stream for all container logs in the kube-system namespace. kjournal pods -n kube-system -w","title":"Try it using kind"},{"location":"tutorials/kind/#try-it-using-kind","text":"This tutorials rolls out a local kind cluster on your computer in order to test kjournal. We will deploy a single node kind control-plane, a single elasticsearch instance as well as fluent-bit for shipping.","title":"Try it using kind"},{"location":"tutorials/kind/#requirements","text":"During this tutorial you need the following tools. Make sure you have them up-to-date. kubectl kustomize kind git kjournal","title":"Requirements"},{"location":"tutorials/kind/#fetch-the-repo","text":"First lets clone the kjournal repository where we can access the deployment files for this tutorial. git clone https://github.com/raffis/kjournal cd kjournal","title":"Fetch the repo"},{"location":"tutorials/kind/#create-kind-cluster","text":"Let's create the kind cluster named kjournal first. Once the control plane is running we can continue. The apiserver is configured to log audit logs which is required if we want to query audit logs as well. kind create cluster --config config/kind-example/control-plane.yaml","title":"Create kind cluster"},{"location":"tutorials/kind/#deploy-kjournal-and-third-party-components","text":"Next we deploy elasticsearch, fluent-bit, kubernetes-event-exporter as well as the kjournal apiserver itself from an opinated kustomize overlay. kustomize build config/kind-example --enable-helm | kubectl apply -f -","title":"Deploy kjournal and third party components"},{"location":"tutorials/kind/#test-kjournal","text":"Last but not least we can test if kjournal works properly. This command will start a watch stream for all container logs in the kube-system namespace. kjournal pods -n kube-system -w","title":"Test kjournal"}]}